<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[go_helloword.md]]></title>
    <url>%2F2020%2F03%2F27%2Fgo-helloword-md%2F</url>
    <content type="text"><![CDATA[go 语言第一个程序go语言规范go程序规范go语言以包作为管理单位每个文件必须声明包程序必须有一个main包(重要) go工程规范go入口，go有且只有一个入口函数main 一个文件里面只能有一个main函数 干活 执行函数 12345678910111213package mainimport "fmt"//入口函数func main() //打印 //"hello go"打印到屏幕，PrintLn()会自动换行 //调用函数，大部分都需要导入包 /* 这也是注释，这是块注释 */ fmt.PrintLn("hello go") //go语言语句结尾是没有分号的 fmt.PirintLn("hello bds")&#125; 12go build xxx.go //通过编译xxx.go文件 然后生成一个以xx为名字的程序 直接执行xxx程序 输出程序结果go run xxx.go //通过run 不生成程序 执行运行 一次性输出程序结果 12345678910111213141516###示例➜ main go build hello.go➜ main ./hellohello.中国➜ main lshello hello.go value1 value1.go➜ main rm -fr hello➜ main lltotal 3744-rw-r--r-- 1 budongshu staff 74B 10 16 14:04 hello.go-rwxr-xr-x 1 budongshu staff 1.8M 10 16 16:47 value1-rw-r--r-- 1 budongshu staff 124B 10 16 16:46 value1.go➜ main go run hello.gohello.中国➜ main lshello.go value1 value1.go go数据类型计算机用来计算，计算前需要存数，如何存一个数呢 数据类型作用: 告诉编译器这个数(变量) 应该以多大的内存存储 命名go 语言中函数名 变量名 常量名 类型名 语句标号和包名等所有的命名，都遵循一个简单的 命名规则: 一个名字必须以一个字母或者下划线开头，后面可以跟任意数量的字母，数字 或者下划线。大写字母和小写字母是不同的，heapSort Heapsort 是俩个不同的变量名字 1234567891011121314151617181920212223242526import "fmt" //导入包的时候必须要使用func main() &#123; //变量，程序运行期间，可以改变的量 //声明格式: var 变量名 类型; 变量声明了，必须要使用 //声明变量没有初始化的变量，默认值为0 //同一个函数的&#123;&#125;里，声明的变量名是唯一的，不允许同名 var a int fmt.Println("a = ",a) //可以同时声明多个变量 //var b,c int a = 10 //变量的赋值 fmt.Println("a = ",a) //变量的初始化： 声明变量时候，同时赋值 var b int = 10 //初始化: 声明变量时，同时赋值(一步到位) b = 20 //赋值: 先声明，后赋值 fmt.Println("b = ",b) // 自动推导类型，必须初始化，因为它是通过初始化的值来确定类型 c := 30 //%T 打印变量的所属类型 fmt.Printf("c type is %T\n",c)&#125;]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cachecloud_redis4.0]]></title>
    <url>%2F2020%2F03%2F27%2Fcachecloud-redis4-0%2F</url>
    <content type="text"><![CDATA[12345cachecloud tag1.2mysql5.7maven3.6jdk1.7+redis4.0 cachecloud12cd /root/git clone https://github.com/sohutv/cachecloud.git mysql5.7.211234567891011121314# wget http://dev.mysql.com/get/mysql57-community-release-el6-8.noarch.rpm# yum install mysql-community-server mysql-community-client# /etc/init.d/mysqld start# grep 'temporary password' /var/log/mysqld.log# mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'tester';# mysql&gt; create database cachecloud default character set utf8 collate utf8_bin;# mysql&gt; use cachecloud;# mysql&gt; source /root/cachecloud/script/cachecloud.sql;# mysql&gt; show tables;# grant all privileges on *.* to 'admin'@'localhost' identified by 'admin';# grant all privileges on *.* to 'admin'@'127.0.0.1' identified by 'admin';# flush privileges; maven3.61234wget http://mirrors.shu.edu.cn/apache/maven/maven-3/3.6.0/binaries/apache-maven-3.6.0-bin.tar.gztar xf apache-maven-3.6.0-bin.tar.gzmv apache-maven-3.6.0 /Data/apps/mavenln -sv /Data/apps/maven/bin/mvn /sbin/mvn jdk1.812345678cd /opt/ &amp;&amp; wget https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk-8u201-linux-x64.tar.gztar xf jdk-8u201-linux-x64.tar.gz#vim /etc/profileexport JAVA_HOME=/opt/jdk1.8.0_111export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATHsource /etc/profile 1java -version cachecloud配置cachecloud配置文件properties修改1234#用户生产使用/root/cachecloud/cachecloud-open-web/src/main/swap/online.properties#用户本地测试使用/root/cachecloud/cachecloud-open-web/src/main/swap/local.properties 12345678910111213vim /root/cachecloud/cachecloud-open-web/src/main/swap/online.propertiescachecloud.db.url = jdbc:mysql://127.0.0.1:3306/cachecloud #修改数据库的名字，注意空格cachecloud.db.user = admin #数据库访问的用户cachecloud.db.password = admin #数据库访问的密码cachecloud.maxPoolSize = 20isClustered = trueisDebug = falsespring-file=classpath:spring/spring-online.xmllog_base=/opt/cachecloud-web/logsweb.port=8585log.level=WARN 123456789101112vim /root/cachecloud/cachecloud-open-web/src/main/swap/local.propertiescachecloud.db.url = jdbc:mysql://127.0.0.1:3306/cachecloudcachecloud.db.user = admincachecloud.db.password = admincachecloud.maxPoolSize = 20isClustered = trueisDebug = truespring-file = classpath:spring/spring-local.xmllog_base = /opt/cachecloud-web/logsweb.port = 9999log.level = INFO cachecloud源码安装启动本地测试配置123456在/root/cachecloud/根目录下运行cd /root/cachecloud/mvn clean compile install -Plocal在cachecloud-open-web模块下运行cd /root/cachecloud/cachecloud-open-webmvn spring-boot:run 生产环境配置12345678在cachecloud根目录下运行cd /root/cachecloud/mvn clean compile install -Ponline# 新建cachecloud 安装服务目录mkdir -p /opt/cachecloud-web# 拷贝cachecloud 配置文件和cachecloud war包cp /root/cachecloud/cachecloud-open-web/src/main/resources/cachecloud-web.conf /opt/cachecloud-web/cp /root/cachecloud/cachecloud-open-web/target/cachecloud-open-web-1.0-SNAPSHOT.war /opt/cachecloud-web/ 启动使用系统服务启动12ln -s /opt/cachecloud-web/cachecloud-open-web-1.0-SNAPSHOT.war /etc/init.d/cachecloud-web/etc/init.d/cachecloud-web start 启动脚本服务启动12345启动方法2(使用脚本启动，大部分操作系统都正常)cp /root/cachecloud/script/start.sh /opt/cachecloud-web/cp /root/cachecloud/script/stop.sh /opt/cachecloud-web/sh start.sh #如果机器内存不足，修改start.sh脚本，可以适当调小:-Xmx和-Xms(默认是4g)sh stop.sh 访问cachecloud 界面12http://10.1.21.169/8585用户名和密码都是 admin 新建redis集群cachecloud 是使用ssh方式来管理主机机器的，所以我们这里通过用户名和密码的方式来管理机器 下面的脚本会自动安装redis服务，并且建立用户和给用户创建密码(根据提示需要自己手动输入密码) redis4.0123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899cat /opt/cachecloud-init.sh ### 这个脚本在cd /root/cachecloud/scripts/ 中#!/bin/bash############################################################################# @desc:# - 1. create user;# - 2. create default directories and authorize;# - 3. @usage: sh cachecloud-init.sh [username]# @author: leifu# @time:###########################################################################set -o nounsetset -o errexitreadonly redisDir="/opt/cachecloud/redis"#readonly redisTarGz="redis-3.0.7.tar.gz"readonly redisTarGz="redis-4.0.12.tar.gz" ###redis4.0# check if the user existscheckExist() &#123; local num=`cat /etc/passwd | grep -w $1 | wc -l` #cat /etc/passwd | grep -q "$1" if [[ $num == 1 ]]; then echo "user $1 exists, overwrite user and *init all data*: [y/n]?" read replace if [[ $&#123;replace&#125; == "y" ]]; then echo "delete existed user: $1." userdel -r "$1" createUser "$1" init "$1" return 0 fi else createUser "$1" init "$1" fi return 0&#125;# create the usercreateUser() &#123; # create a user useradd -m -d /home/$1 -s /bin/bash $1 # give the user a password passwd $1 # add the user to sudoers # echo "$1 ALL=(ALL) ALL" &gt;&gt; /etc/sudoers # Maximum number of days between password change chage -M 9999 $1 echo "OK: create user: $1 done"&#125;# create defautl dirs and authorizeinit() &#123; # create working dirs and a tmp dir mkdir -p /opt/cachecloud/data mkdir -p /opt/cachecloud/conf mkdir -p /opt/cachecloud/logs mkdir -p /opt/cachecloud/redis mkdir -p /tmp/cachecloud # change owner chown -R $1:$1 /opt/cachecloud chown -R $1:$1 /tmp/cachecloud echo "OK: init: $1 done"&#125;# install redisinstallRedis() &#123; #which redis-server #if [[ $? == 0 ]]; then # echo "WARN: redis is already installed, exit." # return #fi yum install -y gcc mkdir -p $&#123;redisDir&#125; &amp;&amp; cd $&#123;redisDir&#125; wget http://download.redis.io/releases/$&#123;redisTarGz&#125; &amp;&amp; mv $&#123;redisTarGz&#125; redis.tar.gz &amp;&amp; tar zxvf redis.tar.gz --strip-component=1 make &amp;&amp; make install if [[ $? == 0 ]]; then echo "OK: redis is installed, exit." chown -R $1:$1 $&#123;redisDir&#125; export PATH=$PATH:$&#123;redisDir&#125;/src return fi echo "ERROR: redis is NOT installed, exit."&#125;username=$1checkExist "$&#123;username&#125;"installRedis "$&#123;username&#125;" 执行安装redis初始化脚本 1sh /opt/cachecloud-init.sh redis #权限为redis 新建redis用户 添加需要被管理的机器]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6.6_install_kong]]></title>
    <url>%2F2020%2F03%2F27%2FCentos6-6-install-kong%2F</url>
    <content type="text"><![CDATA[版本需求 pgsql 10.x kong 2.0.1 konga master代码 cnpm@6.1.1 (/usr/lib/node_modules/cnpm/lib/parse_argv.js) npm@6.13.7 (/usr/lib/node_modules/cnpm/node_modules/npm/lib/npm.js) node@10.19.0 (/usr/bin/node) pgsql 安装yum 源下载，rpm方式安装12yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-6-x86_64/pgdg-redhat-repo-latest.noarch.rpmyum install postgresql10 &amp;&amp; yum install postgresql10-server 建立数据库目录，初始化pgsql12mkdir /Data/apps/pgsql/10/data -pv/etc/init.d/postgresql-10 initdb -D /Data/apps/pgsql/10/data 更改pgsql配置文件1234pg_hba.conf 访问授权权限文件#postgresql.conf 参数配置文件sed -i &quot;/^#listen_addresses/a\listen_addresses=&apos;*&apos;&quot; /Data/apps/pgsql/10/data/postgresql.confsed -i &apos;/all.*127.0.0.1/ s/ident/trust/&apos; /Data/apps/pgsql/10/data/pg_hba.conf 支持远程主机连接1echo &quot;host kong kong 10.0.0.0/8 md5&quot; &gt;&gt; /Data/apps/pgsql/10/data/pg_hba.conf 启动pgsql1/etc/init.d/postgresql-10 restart 数据库授权123456789sudo -u postgres psqlpgsql 授权kongpostgres=# CREATE USER kong; CREATE DATABASE kong OWNER kong;postgres=# ALTER USER kong WITH PASSWORD &apos;haodfxx&apos;;postgres=# grant all privileges on database kong to kong;pgsql 授权kongapostgres=# CREATE DATABASE konga; CREATE DATABASE konga OWNER konga;postgres=# CREATE USER konga CREATEDB LOGIN PASSWORD &apos;haodfxx&apos;;postgres=# grant all privileges on database konga to konga; 最后重启pgsql1/etc/init.d/postgresql-10 restart kong 安装yum 源下载，rpm方式安装1234567$ sudo yum update -y $ sudo yum install -y wget$ wget https://bintray.com/kong/kong-rpm/rpm -O bintray-kong-kong-rpm.repo $ export major_version=`grep -oE &apos;[0-9]+\.[0-9]+&apos; /etc/redhat-release | cut -d &quot;.&quot; -f1` $ sed -i -e &apos;s/baseurl.*/&amp;\/centos\/&apos;$major_version&apos;&apos;/ bintray-kong-kong-rpm.repo $ sudo mv bintray-kong-kong-rpm.repo /etc/yum.repos.d/ $ sudo yum install -y kong 修改kong配置文件1234567891011$ cat /etc/kong/kong.conf |egrep &quot;^[a-z]+&quot; |grep -v &quot;^$&quot;prefix=/Data/apps/kong #更改生成nginx配置文件目录proxy_listen = 0.0.0.0:8100 reuseport backlog=16384, 0.0.0.0:8443 http2 ssl reuseport backlog=16384admin_listen = 0.0.0.0:8101 reuseport backlog=16384, 0.0.0.0:8444 http2 ssl reuseport backlog=16384nginx_user = avatar avatar # Defines user and group credentials used bypg_host = 10.3.19.129 # Host of the Postgres server.pg_port = 5432 # Port of the Postgres server.pg_timeout = 5000 # Defines the timeout (in ms), for connecting,pg_user = kong # Postgres user.pg_password = xxx # Postgres user&apos;s password.pg_database = kong # The database name to connect to. 初始化导入数据库结构1/usr/local/bin/kong migrations bootstrap -c /etc/kong/kong.conf 启动kong服务1/usr/local/bin/kong start -c /etc/kong/kong.conf curl方式验证访问1curl -s http://127.0.0.1:8001/status ｜ python -m json.tool konga 安装123通过git 拉取最新稳定源码 安装kongacd /Data/apps/ #根据线上规则指定目录git clone https://github.com/pantsel/konga.git 安装node npm12curl --silent --location https://rpm.nodesource.com/setup_10.x | bash -cd /Data/apps/konga/ 更改npm 下载源为淘宝源,并且命令为 npm -&gt; cnpm1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装pm2管理服务程序1234cnpm i pm2 -g进入konga目录 ,安装依赖包cd /Data/apps/kongacnpm i 修改konga的env 文件12345678910cd /Data/apps/kongacp .env_example .env配置如下PORT=1337NODE_ENV=productionKONGA_HOOK_TIMEOUT=120000DB_ADAPTER=postgresDB_URI=postgresql://konga:33af103aef686c7fcba09b810b2424c7@localhost:5432/kongaKONGA_LOG_LEVEL=warnTOKEN_SECRET=some_secret_token 初始化konga数据1node ./bin/konga.js prepare --adapter postgres --uri postgresql://konga:33af103aef686c7fcba09b810b2424c7@127.0.0.1:5432/konga 启动konga程序1pm2 start app.js --name konga konga服务 web访问验证1web 访问http://IPxxx:1337/]]></content>
      <categories>
        <category>kong</category>
      </categories>
      <tags>
        <tag>kong</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s_glusterfs几种方式]]></title>
    <url>%2F2020%2F03%2F27%2Fk8s_glusterfs%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[[toc]本文介绍前俩种方式k8s和glusterfs 使用的几种方式 现有外部glusterfs物理集群,k8s通过endpoints,service方式使用,需要手动创建pv,pvc(静态分配存储方式) 现有外部glusterfs物理集群,并且有空余磁盘分区(同意支持初始化的磁盘),使用heketi来管理glusterfs集群通过StorageClass,pvc动态创建pv(heketi安装方式通过物理二进制方式安装,或者docker compose安装) 无外部glusterfs集群,glusterfs和heketi全部使用容器pod 方式来进行管理生命周期(支持动态创建pv,与2一样) k8s直接使用外部glusterfs集群外部搭建glusterfs 略k8s创建endpoints和service1234567891011121314151617181920212223apiVersion: v1kind: Endpointsmetadata: name: gfs-clustersubsets:- addresses: - ip: 10.1.0.27 - ip: 10.1.0.251 ports: - port: 49152 protocol: TCP---apiVersion: v1kind: Servicemetadata: name: gfs-clusterspec: ports: - port: 49152 protocol: TCP targetPort: 49152 sessionAffinity: None type: ClusterIP 创建pv,pvc12345678910111213141516171819202122232425262728apiVersion: v1kind: PersistentVolumemetadata: name: gfs-cluster-pv1 labels: type: glusterfsspec: storageClassName: gfs-pvc1 capacity: storage: 1Gi accessModes: - ReadWriteMany glusterfs: endpoints: &quot;gluster-cluster&quot; path: &quot;k8svol1&quot; readOnly: false---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: gfs-cluster-pvc1spec: storageClassName: gfs-pvc1 accessModes: - ReadWriteMany resources: requests: storage: 1Gi 创建一个pod 测试1234567891011121314151617181920212223242526272829303132kind: Deploymentmetadata: name: pv1-default-t1 labels: app.name: pv1-default-t1spec: replicas: 1 selector: matchLabels: app.name: pv1-default-t1 template: metadata: labels: app.name: pv1-default-t1 spec: containers: - name: nginx-test image: nginx ports: - containerPort: 80 volumeMounts: - name: glusterfsvol mountPath: &quot;/mnt/gfs1&quot; # subPath: glusterfsvol #- name: glusterfsvol # mountPath: &quot;/usr/share/nginx/html/&quot; # subPath: &quot;glusterfsvol1&quot; volumes: - name: glusterfsvol persistentVolumeClaim: claimName: gfs-cluster-pvc1 遇到报错 暂时没有解决 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061[root@k8s-master01 gfs]# kubectl describe pod pv1-default-t1-67548d998d-9vdwgName: pv1-default-t1-67548d998d-9vdwgNamespace: defaultPriority: 0Node: k8s-node01/10.1.1.32Start Time: Thu, 05 Mar 2020 02:43:49 -0500Labels: app.name=pv1-default-t1 pod-template-hash=67548d998dAnnotations: &lt;none&gt;Status: PendingIP:Controlled By: ReplicaSet/pv1-default-t1-67548d998dContainers: nginx-test: Container ID: Image: nginx Image ID: Port: 80/TCP Host Port: 0/TCP State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Environment: &lt;none&gt; Mounts: /mnt/gfs1 from glusterfsvol (rw) /var/run/secrets/kubernetes.io/serviceaccount from default-token-5hm8w (ro)Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled TrueVolumes: glusterfsvol: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: gfs-cluster-pvc1 ReadOnly: false default-token-5hm8w: Type: Secret (a volume populated by a Secret) SecretName: default-token-5hm8w Optional: falseQoS Class: BestEffortNode-Selectors: &lt;none&gt;Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300sEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedMount 17m (x223 over 21h) kubelet, k8s-node01 Unable to mount volumes for pod &quot;pv1-default-t1-67548d998d-9vdwg_default(598bfcf6-96dc-4509-a6b6-0bdf881fb07e)&quot;: timeout expired waiting for volumes to attach or mount for pod &quot;default&quot;/&quot;pv1-default-t1-67548d998d-9vdwg&quot;. list of unmounted volumes=[glusterfsvol]. list of unattached volumes=[glusterfsvol default-token-5hm8w] Warning FailedMount 100s (x367 over 21h) kubelet, k8s-node01 (combined from similar events): MountVolume.SetUp failed for volume &quot;gfs-cluster-pv1&quot; : mount failed: mount failed: exit status 1Mounting command: systemd-runMounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/598bfcf6-96dc-4509-a6b6-0bdf881fb07e/volumes/kubernetes.io~glusterfs/gfs-cluster-pv1 --scope -- mount -t glusterfs -o auto_unmount,backup-volfile-servers=10.1.1.41:10.1.1.42,log-file=/var/lib/kubelet/plugins/kubernetes.io/glusterfs/gfs-cluster-pv1/pv1-default-t1-67548d998d-9vdwg-glusterfs.log,log-level=ERROR 10.1.1.42:k8svol1 /var/lib/kubelet/pods/598bfcf6-96dc-4509-a6b6-0bdf881fb07e/volumes/kubernetes.io~glusterfs/gfs-cluster-pv1Output: Running scope as unit run-28009.scope.[2020-03-06 05:18:36.190120] E [glusterfsd.c:834:gf_remember_backup_volfile_server] 0-glusterfs: failed to set volfile server: File existsMounting glusterfs on /var/lib/kubelet/pods/598bfcf6-96dc-4509-a6b6-0bdf881fb07e/volumes/kubernetes.io~glusterfs/gfs-cluster-pv1 failed., the following error information was pulled from the glusterfs log to help diagnose this issue:[2020-03-06 05:18:36.209244] E [glusterfsd-mgmt.c:2217:mgmt_getspec_cbk] 0-glusterfs: failed to get the &apos;volume file&apos; from server[2020-03-06 05:18:36.209295] E [glusterfsd-mgmt.c:2416:mgmt_getspec_cbk] 0-mgmt: failed to fetch volume file (key:k8svol1) k8s使用外部glusterfs集群和heketi glusterfs7 版本 centos7 系统 机器 安装环境 磁盘 10.1.0.51 glusterfs-server heketi heketi-client /dev/vdb 600G 10.1.0.52 glusterfs-server heketi-client /dev/vdb 600G 10.1.0.53 glusterfs-server heketi-client /dev/vdb 600G 其他节点 glusterfs-fuse heketi-client gfs7 下载仓库glusterfs7.repo123456789101112131415[centos-gluster7]name=CentOS-$releasever - Gluster7baseurl=https://buildlogs.centos.org/centos/7/storage/x86_64/gluster-7/#baseurl=http://mirror.centos.org/centos/$releasever/storage/$basearch/gluster-3.12/gpgcheck=0enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-Storage[centos-gluster7-test]name=CentOS-$releasever - Gluster7 Testingbaseurl=https://buildlogs.centos.org/centos/7/storage/x86_64/gluster-7/gluster-7/gpgcheck=0enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-Storage 或者1yum install centos-release-gluster7 下载安装 heketi物理节点安装heketi heketi-client gfs集群所有节点安装heketi-client glusterfs-server k8s集群所有节点安装heketi-client glusterfs-fuse 也可以所有机器一律安装,命令如下:1yum install glusterfs-server heketi heketi-client heketi topology 初始化集群保证gfs集群有空余磁盘分区,并且磁盘分区一定不要挂载,heketi内部会使用pvcreate来针对这个空余磁盘分区创建volume. 配置启动heketi服务heketi连接glusterfs有三中模式,因为使用的是外部glusterfs集群,所有这里使用第二种模式ssh方式,第一种适用于开发环境,不适用生产,第三种是glusterfs集群容器方式,连接kuberneters使用. 123456789101112131415161718192021222324252627282930313233343536373839404142&#123; &quot;_port_comment&quot;: &quot;Heketi Server Port Number&quot;, &quot;port&quot;: &quot;18080&quot;, &quot;_use_auth&quot;: &quot;Enable JWT authorization. Please enable for deployment&quot;, &quot;use_auth&quot;: true, &quot;_jwt&quot;: &quot;Private keys for access&quot;, &quot;jwt&quot;: &#123; &quot;_admin&quot;: &quot;Admin has access to all APIs&quot;, &quot;admin&quot;: &#123; &quot;key&quot;: &quot;haodf&quot; &#125;, &quot;_user&quot;: &quot;User only has access to /volumes endpoint&quot;, &quot;user&quot;: &#123; &quot;key&quot;: &quot;haodf&quot; &#125; &#125;, &quot;_glusterfs_comment&quot;: &quot;GlusterFS Configuration&quot;, &quot;glusterfs&quot;: &#123; &quot;_sshexec_comment&quot;: &quot;SSH username and private key file information&quot;, &quot;sshexec&quot;: &#123; &quot;keyfile&quot;: &quot;/etc/heketi/heketi_key&quot;, &quot;user&quot;: &quot;root&quot;, &quot;port&quot;: &quot;22&quot;, &quot;fstab&quot;: &quot;/etc/fstab&quot; &#125;, &quot;_db_comment&quot;: &quot;Database file name&quot;, &quot;db&quot;: &quot;/var/lib/heketi/heketi.db&quot;, &quot;_loglevel_comment&quot;: [ &quot;Set log level. Choices are:&quot;, &quot; none, critical, error, warning, info, debug&quot;, &quot;Default is warning&quot; ], &quot;loglevel&quot; : &quot;debug&quot; &#125;&#125; 建立共享密钥,确保heketi节点可以ssh免密钥形式访问glusterfs集群12ssh-keygen -f /etc/heketi/heketi_key -t rsa -N &apos;&apos;cat heketi_key.pub &gt;&gt; /root/.ssh/authorized_keys 拷贝密钥123ssh-copy-id -i /etc/heketi/heketi_key.pub 10.1.0.51ssh-copy-id -i /etc/heketi/heketi_key.pub 10.1.0.52ssh-copy-id -i /etc/heketi/heketi_key.pub 10.1.0.53 启动heketi服务 监听18080端口12nohup /usr/bin/heketi --config=/etc/heketi/heketi.json &amp; curl http://127.0.0.1:18080/hello #测试地址,能够访问,说明服务正常 加载 topology.json配置,建立集群1cat /etc/heketi/topology.json 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&#123; &quot;clusters&quot;:[ &#123; &quot;nodes&quot;:[ &#123; &quot;node&quot;: &#123; &quot;hostnames&quot;:&#123; &quot;manage&quot;:[ &quot;10.1.0.51&quot; ], &quot;storage&quot;:[ &quot;10.1.0.51&quot; ] &#125;, &quot;zone&quot;:1 &#125;, &quot;devices&quot;:[ &quot;/dev/vdb&quot; ] &#125;, &#123; &quot;node&quot;: &#123; &quot;hostnames&quot;:&#123; &quot;manage&quot;:[ &quot;10.1.0.52&quot; ], &quot;storage&quot;:[ &quot;10.1.0.52&quot; ] &#125;, &quot;zone&quot;:1 &#125;, &quot;devices&quot;:[ &quot;/dev/vdb&quot; ] &#125;, &#123; &quot;node&quot;: &#123; &quot;hostnames&quot;:&#123; &quot;manage&quot;:[ &quot;10.1.0.53&quot; ], &quot;storage&quot;:[ &quot;10.1.0.53&quot; ] &#125;, &quot;zone&quot;:1 &#125;, &quot;devices&quot;:[ &quot;/dev/vdb&quot; ] &#125; ] &#125; ]&#125; 1heketi-cli -s http://127.0.0.1:18080 --user admin --secret haodf topology load --json=/etc/heketi/topology.json 上面操作遇到下面问题,请确保是否有挂载新硬盘,且未分区初始化 1initialized or contains data?): WARNING: Device /dev/centos/root not initialized in udev database 解决问题123456df -h |grep /dev/vdb #如果有分区挂载,请卸载/Data/gfs1 xxG /dev/vdbumount /Data/gfs1 执行下面命令wipefs -a /dev/vdb 查看集群,node,volume信息123456789101112131415export HEKETI_CLI_SERVER=http://10.10.249.63:8080#cluster集群信息[root@master01 ~]# heketi-cli -s http://127.0.0.1:18080 --user admin --secret haodf cluster listClusters:Id:c5a894a3dac347affdaecdd637dbdd8b [file][block]#node节点信息[root@master01 ~]# heketi-cli -s http://127.0.0.1:18080 --user admin --secret haodf node listId:3cdda17f46696f3e9f482d2dc850b5a4 Cluster:c5a894a3dac347affdaecdd637dbdd8bId:882b507ffaef33af34edd4effbbda770 Cluster:c5a894a3dac347affdaecdd637dbdd8bId:df0788cba87985c3ea95bcf5e77f1ba0 Cluster:c5a894a3dac347affdaecdd637dbdd8b#volume 信息[root@master01 ~]# heketi-cli -s http://127.0.0.1:18080 --user admin --secret haodf volume listId:22a171e8e15bf07d5f0f388297873a2a Cluster:c5a894a3dac347affdaecdd637dbdd8b Name:vol_22a171e8e15bf07d5f0f388297873a2a 查看某个node节点的device信息123456789101112131415161718192021222324252627#node节点[root@master01 ~]# heketi-cli -s http://127.0.0.1:18080 --user admin --secret haodf node listId:3cdda17f46696f3e9f482d2dc850b5a4 Cluster:c5a894a3dac347affdaecdd637dbdd8bId:882b507ffaef33af34edd4effbbda770 Cluster:c5a894a3dac347affdaecdd637dbdd8bId:df0788cba87985c3ea95bcf5e77f1ba0 Cluster:c5a894a3dac347affdaecdd637dbdd8b#某个node节点信息[root@master01 ~]# heketi-cli -s http://127.0.0.1:18080 --user admin --secret haodf node info 3cdda17f46696f3e9f482d2dc850b5a4Node Id: 3cdda17f46696f3e9f482d2dc850b5a4State: onlineCluster Id: c5a894a3dac347affdaecdd637dbdd8bZone: 1Management Hostname: 10.1.0.53Storage Hostname: 10.1.0.53Devices:Id:22889a4d302bc9403878317060f46d35 Name:/dev/vdb State:online Size (GiB):599 Used (GiB):1 Free (GiB):598 Bricks:1#某个node节点的device信息[root@master01 ~]# heketi-cli -s http://127.0.0.1:18080 --user admin --secret haodf device info 22889a4d302bc9403878317060f46d35Device Id: 22889a4d302bc9403878317060f46d35Name: /dev/vdbState: onlineSize (GiB): 599Used (GiB): 1Free (GiB): 598Bricks:Id:f9bf5d4e5c2ae8efd79d29c208000505 Size (GiB):1 Path: /var/lib/heketi/mounts/vg_22889a4d302bc9403878317060f46d35/brick_f9bf5d4e5c2ae8efd79d29c208000505/brick 建立StorageClass12345678910111213apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: gluster-heketi-storageclass namespace: storageprovisioner: kubernetes.io/glusterfsreclaimPolicy: Retainparameters: resturl: &quot;http://10.1.0.51:18080&quot; restauthenabled: &quot;true&quot; restuser: &quot;admin&quot; restuserkey: &quot;haodf&quot; volumetype: &quot;replicate:3&quot; 建立pvc1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: pvc-gluster-heketispec: storageClassName: gluster-heketi-storageclass accessModes: - ReadWriteOnce resources: requests: storage: 1Gi 建立nginx pod测试1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: nginx-pod labels: name: nginx-podspec: containers: - name: nginx-pod image: nginx:1.16.0-alpine ports: - name: web containerPort: 90 volumeMounts: - name: gluster-test mountPath: /usr/share/nginx/html/ volumes: - name: gluster-test persistentVolumeClaim: claimName: pvc-gluster-heketi 模拟heketi故障kill杀掉进程 1ps aux |grep heketi|grep -v grep |grep heketi.json |awk &apos;&#123;print $2&#125;&apos; |xargs kill -9 pod 正常写入,删除,查看,已经挂载集群的不受影响因为可以看到pod内部已经mount挂载glusterfs集群.12345678910111213[root@master01 gluster-kubernetes]# kubectl exec -it nginx-pod -- /bin/sh/ # cd /usr/share/nginx/html//usr/share/nginx/html # lsa test test1/usr/share/nginx/html # echo bds &gt; test3/usr/share/nginx/html # cat test1b/usr/share/nginx/html # rm -f test1/usr/share/nginx/html # lsa test test2 test3#查看mount 挂载/usr/share/nginx/html # mount |grep glu10.1.0.53:vol_22a171e8e15bf07d5f0f388297873a2a on /usr/share/nginx/html type fuse.glusterfs (rw,relatime,user_id=0,group_id=0,default_permissions,allow_other,max_read=131072) 试试新建pvc可以看到一直处于,pending状态,对于新建pvc有影响1234[root@master01 gluster-kubernetes]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEpvc-gluster-heketi Bound pvc-9d4133cb-0057-4bf0-9113-5c5bff1b193d 1Gi RWO gluster-heketi-storageclass 13hpvc1-gluster-heketi Pending gluster-heketi-storageclass 60s 这时候启动heketi,再次看下pvc状态1234567#删除pending pvc[root@master01 gluster-kubernetes]# kubectl delete -f gfs-heketi/pvc1-gluser-heketi.yamlpersistentvolumeclaim &quot;pvc1-gluster-heketi&quot; deleted#再次创建[root@master01 gluster-kubernetes]# kubectl apply -f gfs-heketi/pvc1-gluser-heketi.yamlpersistentvolumeclaim/pvc1-gluster-heketi created 1234567经过删除,再次重建,发现pvc可以自动创建pv[root@master01 gluster-kubernetes]# kubectl get pvc -wNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEpvc-gluster-heketi Bound pvc-9d4133cb-0057-4bf0-9113-5c5bff1b193d 1Gi RWO gluster-heketi-storageclass 13hpvc1-gluster-heketi Pending gluster-heketi-storageclass 16spvc1-gluster-heketi Pending pvc-49192bd4-933f-46a5-9f7c-72777f8801f4 0 gluster-heketi-storageclass 26spvc1-gluster-heketi Bound pvc-49192bd4-933f-46a5-9f7c-72777f8801f4 1Gi RWO gluster-heketi-storageclass 26s 测试证明(heketi服务故障) 不影响已经创建的pvc,并且挂载pv的容器使用 影响新建pvc的使用 回到标题1]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 安装]]></title>
    <url>%2F2018%2F04%2F25%2Fdocker_install%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[机器环境 容器管理工具 Docker Engine runtime - runc Docker默认的runtime 操作系统 CentOS 7.2.1511 (3.10.0-327.el7.x86_64) docker 安装 由于docker社区版本迭代很快，最近也发生很多变化，所以在安装之前想说明一下现在的版本情况 docker 版本说明docker自1.13版本以后发行版本有了很大不同分为: CE(community edition)社区版 EE(enterprise edition)企业版 docker 版本号说明 现在Docker改为基于YY.MM的版本（像Ubuntu） 用户可以选择Stable（发布较慢）或者Edge（发布较快）版本。 ce由社区维护和提供技术支持，为免费版本 ee版本为收费版本，由售后团队和技术团队支持技术支持 更多的收费标准看docker官网 docker 安装包说明 docker.io is used to be very old version in default ubuntu repo (can skip here) docker-engine: is used before release 1.13.x docker-ce: since 17.03 docker engine安装(旧版本安装）yum 安装 123456789cat &gt; /etc/yum.repos.d/docker.repo &lt;&lt;EOF[dockerrepo]name=Docker Repositorybaseurl=https://mirrors.aliyun.com/docker-engine/yum/repo/main/centos/7/enabled=1gpgcheck=0gpgkey=https://yum.dockerproject.org/gpgEOF 1yum -y install docker-engine 启动管理 123systemctl start dockersystemctl enable dockersystemctl status docker docker-ce 安装(正式进入新版本安装方式)阿里云安装脚本12curl -fsSL get.docker.com -o get-docker.sh #下载get-docker.sh文件sudo sh get-docker.sh --mirror Aliyun #以阿里云镜像安装get-docker.sh脚本内容 yum 安装 安装所需的软件包 yum-utils提供了yum-config-manager 作用并device-mapper-persistent-data和lvm2由需要devicemapper存储驱动程序。 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 添加镜像源 1sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 将软件包添加至本地缓存 1sudo yum makecache fast 安装docker-ce 1sudo yum install docker-ce 启动docker 1sudo systemctl start docker rpm 安装下载地址: docker rpm包 (阿西巴,需要翻墙了) daocloud 安装下载地址: https://get.daocloud.io/#install-docker 1curl -sSL https://get.daocloud.io/docker | sh 安装后查看详细信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@bds-aliyun ~]# docker infoContainers: 1 Running: 0 Paused: 0 Stopped: 1Images: 3Server Version: 17.12.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: seccomp Profile: defaultKernel Version: 3.10.0-693.2.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 992.3MiBName: bds-aliyunID: 3SA2:4HKN:CQU3:QG7O:ZJ73:77JU:PHBG:QBUY:VRWX:D6O7:BAG4:3IF5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: http://08b61f14.m.daocloud.io/Live Restore Enabled: falseWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disable Registy 加速需要注册daocloud官网 1curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://xxxx.m.daocloud.io Docker hub国内加速 1官方地址: https://docs.docker.com/registry/recipes/mirror/#configure-the-docker-daemon 阿里云加速 1官方地址: https://cr.console.aliyun.com/#/accelerator docker 拉取镜像1docker pull nginx 启动nginx123456789101112[root@bds-aliyun ~]# docker pull nginxUsing default tag: latestlatest: Pulling from library/nginx2a72cbf407d6: Pull complete04b2d3302d48: Pull completee7f619103861: Pull completeDigest: sha256:cb29ee85b234f356fb8a77d8cfb78b42355f7f016f528f11a2a5f75e4862dc94Status: Downloaded newer image for nginx:latest[root@bds-aliyun ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest b175e7467d66 2 weeks ago 109MB[root@bds-aliyun ~]# docker run -p 81:80 nginx 请求nginx12345678910111213141516另起终端本地访问启动的nginx[root@bds-aliyun ~]# curl -I http://172.17.233.88:81HTTP/1.1 200 OKServer: nginx/1.13.12Date: Wed, 25 Apr 2018 05:38:42 GMTContent-Type: text/htmlContent-Length: 612Last-Modified: Mon, 09 Apr 2018 16:01:09 GMTConnection: keep-aliveETag: &quot;5acb8e45-264&quot;Accept-Ranges: bytes 终端日志输出[root@bds-aliyun ~]# docker run -p 81:80 nginx172.17.233.88 - - [25/Apr/2018:05:38:35 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.29.0&quot; &quot;-&quot;172.17.233.88 - - [25/Apr/2018:05:38:42 +0000] &quot;HEAD / HTTP/1.1&quot; 200 0 &quot;-&quot; &quot;curl/7.29.0&quot; &quot;-&quot; 进入容器 修改nginx html文件12345678910[root@bds-aliyun ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5bd99fe2480d nginx &quot;nginx -g &apos;daemon of…&quot; 9 minutes ago Up 9 minutes 0.0.0.0:81-&gt;80/tcp unruffled_murdock[root@bds-aliyun ~]# docker exec -it 5bd99fe2480d bashroot@5bd99fe2480d:/# cd /usr/share/nginx/html/root@5bd99fe2480d:/usr/share/nginx/html# echo budongshu jianshu &gt; index.htmlroot@5bd99fe2480d:/usr/share/nginx/html# exitexit[root@bds-aliyun ~]# curl http://172.17.233.88:81budongshu jianshu 通过curl命令测试 通过网页访问]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 入门简介]]></title>
    <url>%2F2018%2F04%2F24%2Fdocker_container%E5%AE%B9%E5%99%A8%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[云计算平台 IaaS 虚拟机 存储 负载均衡 网络 PaaS 运行时环境 数据库 web服务器 开发工具 SaaS 客户关系管理 邮件 虚拟桌面 通信 游戏 IaaS理解为基础设施运维人员服务，提供计算 存储 网络以及其他基础资源，云平台使用者可以在上面部署和运行包括操作系统和应用程序在内的任意软件，无需再为基础设施的管理而分心 Paas应用开发人员服务，提供支撑应用运行所需要的软件运行时环境，相关工具与服务，如数据库服务，日志服务 监控服务等，让应用开发者可以专注于核心业务的开发 SaaS一般用户服务，提供了一套完整可用的软件系统，让一般用户无需关注技术细节，只需要通过浏览器应用客户端等方式 就能使用部署在云上的应用服务 容器最新的容器技术引入了 OpenVZ Solaris Zones 以及 Linux容器（如lxc）使用这些新技术，容器不再仅仅是一个单纯的运行环境，在自己的权限范围内，容器更像是一个完整的宿主机，对Docker来说，它得益于现在Linux内核特性，如控制组(control group),命名空间(namespace) 技术，容器和宿主机之间的隔离更加彻底，容器有独立的网络和存储栈，还拥有自己的资源管理能力，使得同一台宿主机中的多个容器可以友好的地共存 容器需要的开销资源有限，和传统的虚拟化以及半虚拟化技术(paravirtualization)相比，容器运行不需要模拟(emulation layer）和管理层（hypervisor layer），而是使用操作通的系统调用接口，这降低了运行单个容器所需要的开销，也使得宿主机中可以运行更多的容器 容器云容器云以容器为资源分割和调度的基本单位，封装整个软件运行时环境 为开发者和系统管理员提供用于构建 发布和运行分布式应用的平台。当容器云专注于资源共享和隔离，容器编排与部署时候它更近传统的Iaas。当容器云渗透到应用支撑与运行是的环境时， 它更接近于传统的PaaS. 从容器到容器云是一种伟大的进化，并依旧在日积月累中不断前行，现在让我们一起进入Docker世界感受容器和容器云的魅力 docker 简介Docker是一个能够把开发的应用程序自动部署到容器的开源引擎。用于构建 发布 和运行分部署应用的平台，它是一个跨平台 可移植并且简单易用的容器解决方案。 Docker代码托管在GitHub上，基于Go语言开发 并遵从Apache 2.0协议，通过操作系统内核技术(namespaces cgroups)等 为容器提供资源隔离与安全保障。 Docker项目是由Solomon Hykes 所带领的团队发起，在Docker公司的前身dotCloud内部启动孕育代码托管在GitHub。 2013年3月：Docker正式发布开源版本。 docker 特点 持续部署与测试 跨平台支持 环境标准和版本控制 高资源利用率与隔离 容器跨平台性与镜像 易于理解且易用 应用镜像仓库 Containers and virtual machines docker 客户端Docker是一个典型的C/S架构的应用程序，但在发布上 Docker将客户端和服务器端统一在同一个二进制文件中，不过 这只是对于Linux系统而言的 在其他平台上如Mac上，Docker只提供了用户端 Docker客户端一般通过Docker Command来发起请求，另外 也可以通过Docker提供的一整套Restful API来发起请求， 这种方式更多地被应用在应用程序的代码中 docker daemonDocker daemon也可以被理解成DockerServer，另外 人们也常常用Docker Engine来直接描述它，因为这实际上就是驱动整个Docker功能的核心引擎 简单的说，Docker daemon实现的功能就是接收客户端来的请求，并实现请求所要求的功能，同时针对返回相应的结果，在功能的实现上，因为涉及了容器 镜像 存储等多方面的内容daemon内部的机制会复杂很多，涉及多个模块之间的实现和交互 docker 镜像可以理解为类似于传统虚拟化的iso镜像，不过Docker镜像相对要轻量化很多，它只是一个可以定制的rootfs。Docker镜像的另一个创新是 它是层级的 并且是可复用的。如果是基于相同的发行版的镜像，在大多数文件的内容上都是一样的，基于此，当然会希望可以服用他们。利用Unionfs的特性，Docker会极大迪减少磁盘和内存的开销 docker 镜像可以通过Dockerfile来创建的，Dockerfile提供了镜像内容的定制，同时也体现了曾经关系的建立。也可以通过使用docker commit命令来手动将修改后的内容生成镜像这些将在后面详细介绍 RegistryRegistry是一个存放镜像的仓库，它通常部署在互联网服务器上或者云端上 Docker公司提供了官方的Registry叫Docker Hub这上面提供了大多数常用软件和发行版的镜像 Registry本身也是一个开源项目，任务人都可以下载进项部署，所以多数企业选择在自己的内部部署一套自己的Docker Hub 后二次开发。 docker 生态]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6.6 编译安装php7和php扩展]]></title>
    <url>%2F2018%2F04%2F21%2FCentos6.6_%E7%BC%96%E8%AF%91php7andphp7%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[机器环境12CentOS release 6.6 (Final)kernal 2.6.32-504.23.4.el6.x86_64 yumyum install -y curl libcurl-devel libjpeg-devel libpng-devel libjped-devel freetype-devel libxslt-devel boost-devel gperf libevent-devel libuuid-devel libgearman libgearman-devel install php下载目录: /opt/安装目录: /Data/apps/php/ 1234567cd /optwget http://docs.php.net/distributions/php-7.0.28.tar.gztar xf php-7.0.28.tar.gzcd php-7.0.28./configure --with-libdir=lib64 --prefix=/Data/apps/php --with-mysql=mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-gd --with-zlib --with-png-dir --with-jpeg-dir --with-iconv --with-curl --with-mcrypt --with-openssl --with-xsl --enable-opcache --enable-inline-optimization --enable-fpm --enable-mbstring --enable-pcntl --enable-soap --enable-sockets --enable-bcmath --with-libxml --with-freetype-dir=/usr/include/freetype2/ --disable-pharmake &amp;&amp; make install php 扩展 下面所有php扩展包的下载目录统一为: /opt/soft/ opcache1234cd /opt/php-7.0.28/ext /Data/apps/php/bin/phpize./configure --with-php-config=/Data/apps/php/bin/php-configmake &amp;&amp; make install xdebug从2.4开始支持php7 下载地址: https://xdebug.org/files/ 1234567wget https://xdebug.org/files/xdebug-2.6.0.tgztar xf xdebug-2.6.0.tgzcd xdebug-2.6.0/Data/apps/php/bin/phpize./configure --with-php-config=/Data/apps/php/bin/php-configmake make install igbinary最新版本(2.0.5),2.0.1开始支持7.0 详情连接: http://pecl.php.net/package-changelog.php?package=igbinary 1234567wget https://pecl.php.net/get/igbinary-2.0.5.tgztar xf igbinary-2.0.5.tgzcd igbinary-2.0.5/Data/apps/php/bin/phpize./configure --with-php-config=/Data/apps/php/bin/php-configmakemake install memcached123456memcached版本要求： php-memcached 3.x Supports PHP 7.0 - 7.2. Requires libmemcached 1.x or higher. Optionally supports igbinary 2.0 or higher. Optionally supports msgpack 2.0 or higher. 12345安装libmemcached 依赖包wget https://launchpad.net/libmemcached/1.0/1.0.18/+download/libmemcached-1.0.18.tar.gzctar -zxf libmemcached-1.0.18.tar.gz./configure --prefix=/Data/apps/libmemcached --with-memcachedmake &amp;&amp; make install 123456wget https://pecl.php.net/get/memcached-3.0.0.tgztar xf memcached-3.0.0.tgzcd /opt/soft/memcached-3.0.0/Data/apps/php/bin/phpize./configure --with-php-config=/Data/apps/php/bin/php-config --with-libmemcached-dir=/Data/apps/libmemcached --enable-memcached --enable-memcached-igbinary make &amp;&amp; make install 遇到这样的报错configure: error: no, sasl.h is not available. Run configure with --disable-memcached-sasl to disable this check根据提示加上参数重新编译 12./configure --with-php-config=/Data/apps/php/bin/php-config --with-libmemcached-dir=/Data/apps/libmemcached --enable-memcached --enable-memcached-igbinary --disable-memcached-sasl make &amp;&amp; make install imagick下载地址：https://pecl.php.net/package/imagick 123456安装ImageMagick(ImageMagick-7.0.7-28)wget ftp://mirror.checkdomain.de/imagemagick/ImageMagick-7.0.7-28.tar.gztar xf ImageMagick-7.0.7-28.tar.gzcd ImageMagick-7.0.7-28./configure --prefix=/Data/apps/ImageMagickmake &amp;&amp; make install 1234567编译imagickwget http://pecl.php.net/get/imagick-3.4.3.tgztar xf imagick-3.4.3.tgzcd imagick-3.4.3/Data/apps/php/bin/phpize./configure --with-imagick=/Data/apps/ImageMagick --with-php-config=/Data/apps/php/bin/php-configmake &amp;&amp; make install redis下载地址: https://github.com/phpredis/phpredis (develop版本) 安装redis目录: /Data/app/redis 123456编译redis扩展wget https://pecl.php.net/get/redis-3.0.0.tgzcd redis-3.0.0/Data/apps/php/bin/phpize./configure --enable-redis-igbinary=/Data/apps/redis/bin/ --with-php-config=/Data/apps/php/bin/php-configmake &amp;&amp; make install gearman安装gearmand服务端 https://launchpad.net/gearmand 版本：1.1.12 123456编译gearman客服端扩展git下载最新：https://github.com/wcgallego/pecl-gearman/tree/mastercd pecl-gearman-master/Data/apps/php/bin/phpize./configure --with-php-config=/Data/apps/php/bin/php-configmake &amp;&amp; make install scws下载链接：http://www.xunsearch.com/scws/download.php 1234wget http://www.xunsearch.com/scws/down/scws-1.2.3.tar.bz2cd scws-1.2.3/phpext/Data/apps/php/bin/phpize./configure --with-scws=/Data/apps/scws --with-php-config=/Data/apps/php/bin/php-config amqp下载地址: http://pecl.php.net/package/amqp 12345安装rabbitmq-c依赖库wget https://github.com/alanxz/rabbitmq-c/releases/download/v0.8.0/rabbitmq-c-0.8.0.tar.gzcd rabbitmq-c-0.8.0./configure --prefix=/usr/local/rabbitmq-c-0.8.0make &amp;&amp; make install 1234567编译amqp扩展wget https://pecl.php.net/get/amqp-1.9.3.tgztar -xf amqp-1.9.3.tarcd amqp-1.9.3/Data/apps/php/bin/phpize./configure --with-php-config=/Data/apps/php/bin/php-config --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c-0.8.0make &amp;&amp; make install fastdfs client123456wget https://github.com/happyfish100/fastdfs/archive/master.zipunzip master.zipcd fastdfs-master/php_client/Data/apps/php/bin/phpize./configure --with-php-config=/Data/apps/php/bin/php-configmake &amp;&amp; make install libiconv1234567安装libiconvwget http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.14.tar.gztar xf libiconv-1.14.tar.gzcd libiconv-1.14./configure makemake install 12345安装libdatrie解压，进入目录./configure LDFLAGS=-L/usr/local/lib LIBS=-liconv --host=armmakemake install 123456安装trie_filter.so 拓展git clonde https://github.com/zzjin/php-ext-trie-filtercd php-ext-trie-filter/Data/apps/php/bin/phpize./configure --with-php-config=/Data/apps/php/bin/php-config --with-trie_filter=/usr/local/libdatriemake &amp;&amp; make install php.ini 配置12cd /opt/soft/php-7.0.28cp php.ini-production /Data/apps/php/lib/php.ini 1234567891011121314151617181920212223242526272829303132333435363738加载的模块配置[opcache]zend_extension=&quot;/Data/apps/php/lib/php/extensions/no-debug-non-zts-20151012/opcache.so&quot;opcache.memory_consumption=128opcache.interned_strings_buffer=8opcache.max_accelerated_files=4000opcache.fast_shutdown=1opcache.enable_cli=1opcache.validate_timestamps=1opcache.revalidate_freq=1opcache.error_log=&quot;/Data/apps/php/var/log/opcache.log&quot;[memcached]extension=memcached.somemcache.hash_strategy=consistentmemcache.hash_function=crc32session.save_handler = memcachedextension=igbinary.soextension=imagick.soextension=redis.soextension=gearman.soextension=trie_filter.so[scws]extension=scws.soscws.default.charset = utf8scws.default.fpath = /Data/apps/scws/etc[amqp]extension=amqp.so[fastdfs]extension = fastdfs_client.sofastdfs_client.base_path = /tmpfastdfs_client.connect_timeout = 2fastdfs_client.network_timeout = 60fastdfs_client.log_level = infofastdfs_client.http.anti_steal_secret_key =fastdfs_client.tracker_group_count = 1fastdfs_client.tracker_group0 = /etc/fdfs/client.conffastdfs_client.use_connection_pool = falsefastdfs_client.connection_pool_max_idle_time = 3600 php-fpm.conf1cp /Data/apps/php/etc/php-fpm.conf.default /Data/apps/php/etc/php-fpm php-fpm 启动脚本123cd /opt/soft/php-7.0.28/sapi/fpmcp init.d.php-fpm /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpm 启动php1/etc/init.d/php-fpm start]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka_cluster]]></title>
    <url>%2F2018%2F04%2F20%2Fkafka_cluster%2F</url>
    <content type="text"><![CDATA[download elk rpm123456789101112kakfa-manager wget https://excellmedia.dl.sourceforge.net/project/schedulerbox/tmp/scala_dependencies/kafka-manager-1.3.1.6-1.noarch.rpmlogstashwget https://mirrors.tuna.tsinghua.edu.cn/ELK/yum/logstash-2.4/logstash-2.4.0.noarch.rpmelasticsearchhttps://mirrors.tuna.tsinghua.edu.cn/ELK/yum/elasticsearch-2.x/elasticsearch-2.4.0.rpmkinanahttps://mirrors.tuna.tsinghua.edu.cn/ELK/yum/kibana-4.5/kibana-4.5.4-1.x86_64.rpmfilebeathttps://mirrors.tuna.tsinghua.edu.cn/elasticstack/5.x/yum/5.0.0/filebeat-5.0.0-x86_64.rpmelastis-search-head https://codeload.github.com/mobz/elasticsearch-head/zip/master 机器环境123456系统版本centos6.6机器三台搭建集群10.1.1.1110.1.1.1210.1.1.13 以下安装的软件将分别在三台机器进行安装,下面只用一台机器作为例子进行安装。不同的地方会有说明 zookeeper 安装下载并解压zkdownload 地址: https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/ 1234cd /home/root/wget http://archive.apache.org/dist/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gztar xf zookeeper-3.4.9.tar.gzcd zookeeper-3.4.9 创建快照日志和日志目录12mkdir /Data/zookeeper/data -pv mkdir /Data/zookeeper/logs -pv 安装并配置安装目录: /Data/apps/ 1cp -a /root/zookeeper-3.4.9 /Data/apps/zookeeper 配置文件修改 12345678910tickTime=2000initLimit=10syncLimit=5dataDir=/Data/zookeeper/datadataLogDir=/Data/zookeeper/logsclientPort=2181server.1=10.1.1.11:2888:3888server.2=10.1.1.12:2888:3888server.3=10.1.1.13:2888:3888 zk 标识server id目录地址: /Data/zookeeper/data/myid 在目录中创建文件myid文件 每个文件中分别写入当前机器的server id 例如这个机器10.1.1.11 1234将分别在三台机器上执行echo 1 &gt;&gt; /Data/zookeeper/data/myidecho 2 &gt;&gt; /Data/zookeeper/data/myidecho 3 &gt;&gt; /Data/zookeeper/data/myid 启动zookeeper1/Data/apps/zookeeper/bin/zkServer.sh start 检测状态 在各个节点上分别执行如下指令，可看到其中有leader和follower，即搭建成功 1/Data/apps/zookeeper/bin/zkServer.sh status kafka安装DOWNLOAD 地址: http://kafka.apache.org/downloads.html 下载 kafka安装目录: /Data/apps/kafka 分别在三体机器上进行安装 123wget https://archive.apache.org/dist/kafka/0.9.0.1/kafka_2.10-0.9.0.1.tgztar xf kafka_2.10-0.9.0.1.tgzcp -a kafka_2.11-0.9.0.1 /Data/apps/kafka 建立日志目录1mkdir /Data/kafka/kafka-logs 配置文件 kafka12345678910111213141516171819broker.id=0 #集群节点的标示符，不得重复。取值范围0~nhost.name=10.1.1.11 #三个机器分别修改为自己的IP地址port=9092zookeeper.connect=10.1.1.11:2181,10.1.1.12:2181,10.1.1.13:2181default.replication.factor=2num.network.threads=3num.io.threads=8num.partitions=1num.recovery.threads.per.data.dir=1socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/Data/kafka/kafka-logslog.retention.check.interval.ms=300000 log.cleanup.policy=delete #日志的清除策略：直接删除log.retention.hours=72 #日志保存时间为3天log.segment.bytes=1073741824 #每个日志文件的最大的大小，这里为1GBdelete.topic.enable=true #通过配置此项使得删除topic的指令生效zookeeper.connection.timeout.ms=6000 启动 kafka这里注意，记得要先启动zookeeper。确保zookeeper启动以后再执行kafka的启动命令 1/Data/apps/kafka/bin/kafka-server-start.sh -daemon /Data/apps/kafka/config/server.properties 检测kafka进程是否存在1ps aux |grep kafka kafka 常用操作命令Check service推荐第一次启动先不要加上-daemon参数 观察一下控制台输出是否有success 1/Data/apps/kafka/bin/kafka-server-start.sh /Data/apps/kafka/config/server.properties Create topic1bin/kafka-topics.sh --create --zookeeper 10.1.1.11:2181 --replication-factor 3 --partitions 1 --topic bdstest Describe a topic1bin/kafka-topics.sh --describe --zookeeper 10.1.1.11:2181 --topic bdstest List the topic1bin/kafka-console-producer.sh --broker-list 10.1.1.11:9092 --topic bdstest Start a consumer1bin/kafka-console-consumer.sh --zookeeper 10.1.1.11:2181 --topic bdstest --from-beginning Start a consumer1bin/kafka-console-consumer.sh --zookeeper 10.1.1.12:2181 --topic nodeHlsTest --from-beginning Delete a topic要事先在serve.properties 配置 delete.topic.enable=true 1bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic bdstest 如果仍然只是仅仅被标记了删除(zk中并没有被删除)，那么启动zkCli.sh,输入如下指令 1234/Data/apps/zookeeper/bin/zkCli.sh #敲回车进入zookeeper管理终端[zk: localhost:2181(CONNECTED) 0] ls /brokers/topics[test1, test2][zk: localhost:2181(CONNECTED) 1] rmr /brokers/topics/test1]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible-playbook 介绍]]></title>
    <url>%2F2017%2F09%2F07%2Fansible_playbook%20%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[playbook简介playbook是ansible用于配置，部署，和管理被控节点的剧本。通过playbook的详细描述，执行其中的一系列tasks，可以让远端主机达到预期的状态。playbook就像Ansible控制器给被控节点列出的的一系列to-do-list，而被控节点必须要完成。也可以这么理解，playbook 字面意思，即剧本，现实中由演员按照剧本表演，在Ansible中，这次由计算机进行表演，由计算机安装，部署应用，提供对外服务，以及组织计算机处理各种各样的事情。 Playbook使用场景执行一些简单的任务，使用ad-hoc(调用各种模块,通过命令行来执行命令)命令可以方便的解决问题，但是有时一个设施过于复杂，需要大量的操作时候，执行的ad-hoc命令是不适合的，这时最好使用playbook，就像执行shell命令与写shell脚本一样，也可以理解为批处理任务，不过playbook有自己的语法格式，一会会介绍。使用playbook你可以方便的重用这些代码，可以移植到不同的机器上面，像函数一样，最大化的利用代码。在你使用Ansible的过程中，你也会发现，你所处理的大部分操作都是编写playbook。 playbook格式playbook由YMAL语言编写。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822，Clark Evans在2001年5月在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者。 YMAL格式是类似于JSON的文件格式，便于人理解和阅读，同时便于书写。首先学习了解一下YMAL的格式，对我们后面书写playbook很有帮助。以下为playbook常用到的YMAL格式。 YMAL语法请参考http://docs.ansible.com/YAMLSyntax.html yaml格式语法简介对于 Ansible, 每一个 YAML 文件都是从一个列表开始. 列表中的每一项都是一个键值对, 通常它们被称为一个 “哈希” 或 “字典”. 所以, 我们需要知道如何在 YAML 中编写列表和字典. 文件第一行以 —- (三个连字符)开始,表明yaml文件的开始 在同一行中, #之后的内容表示注释, 类似于shell,python yaml中的列表元素以 - 开头然后紧跟着一个空格,后面为元素的内容例子如下: 1234---- apple- red- green 同一个列表中的元素应该保持相同的缩进。否则会被当做错误处理。 play中hosts，variables，roles，tasks等对象的表示方法都是键值中间以”:”分隔表示,”:”后面还要增加一个空格。 YMAL的有很多的字符串可以解释为true或false： 12YMAL Truethy: true ,True ,TRUE ,yes ,Yes , YES ,on ,On ,ON ,y ,YMAL falthy:false ,False ,FALSE ,no ,No ,NO ,off ,Off ,OFF , n ,N 尽管 YAML 通常是友好的, 但是下面将会导致一个 YAML 语法错误: 1foo: somebody said I should put a colon here: so I did 你需要使用引号来包裹任何包含冒号的哈希值, 像这样: 1foo: &quot;somebody said I should put a colon here: so I did&quot; 然后这个冒号将会被结尾. Ansible 使用 “” 来引用变量. 如果一个值以 “{” 开头, YAML 将认为它是一个字典, 所以我们必须引用它, 像这样:foo: “12345---# 一位职工的记录name: Example Developerjob: Developerskill: Elite 让我们把目前所学到的 YAML 例子组合在一起. 这些在 Ansible 中什么也干不了 但这些格式将会给你感觉:123456789101112131415---# 一位职工记录name: Example Developerjob: Developerskill: Eliteemployed: Truefoods:- Apple- Orange- Strawberry- Mangolanguages:ruby: Elitepython: Elitedotnet: Lame 一个家庭记录 playbook基础现在的/etc/ansible/hosts配置12345[root@note1 ansible]# cat /etc/ansible/hosts[web]192.168.70.51[db]192.168.70.50 安装一个mysql服务的案列 在mysql.yml中，主要由三个部分组成: hosts部分：使用hosts指示使用哪个主机或主机组来运行下面的tasks，每个playbook都必须指定hosts，hosts也可以使用通配符格式。主机或主机组在inventory清单中指定，可以使用系统默认的/etc/ansible/hosts，也可以自己编辑，在运行的时候加上-i选项，指定清单的位置即可。在运行清单文件的时候，–list-hosts选项会显示那些主机将会参与执行task的过程中。 remote_user：指定远端主机中的哪个用户来登录远端系统，在远端系统执行task的用户，可以任意指定，也可以使用sudo，但是用户必须要有执行相应task的权限。 tasks：指定远端主机将要执行的一系列动作。tasks的核心为ansible的模块，前面已经提到模块的用法。tasks包含name和要执行的模块，name是可选的，只是为了便于用户阅读，不过还是建议加上去，模块是必须的，同时也要给予模块相应的参数。 playbook运行结果解析使用ansible-playbook运行playbook文件，得到如下输出信息，输出内容为JSON格式。并且由不同颜色组成，便于识别。一般而言 绿色代表执行成功，系统保持原样 黄色代表系统代表系统状态发生改变 红色代表执行失败，显示错误输出。 执行的时候是用ansible-playbook而不是ansible命令了 查看结果 列出执行的远程主机1234[root@note1 ansible]# ansible-playbook mysql_ansible.yaml --list-hostsplaybook: mysql_ansible.yamlplay #1 (db): host count=1192.168.70.50 ansible具有幂等性 再次执行的时候ansible会检测这个task是否已经执行过, 如果这个task任务执行过,它不会再次执行task任务, 而是直接显示ok状态. ansible-playbook 进阶特性playbook 组成结构123456789Invertory ModulesAd Hoc CommandsPlayBooksTasks 任务 即调用模块完成的某操作Variable 变量Templates 模板 根据客户端的情况来生成一些的数据Handlers 处理器 由某条件满足能触发执行的操作Roles 角色 playbook 基础组件Hosts和Usersplaybook中的每一个play的目的都是为了让某个或者某些主机以某个指定的用户身份来执行任务，hosts是用于指定要执行的指定任务的主机，其可以是一个或者多个以冒号分割的主机组，remote_users则用于指定远程主机上的执行任务的用户，如下面所示12- hosts: webnodes remote_user: root 不过 remote_users 也可以用于每个task中，也可以通过指定其通过sudo的方式在远程的主机上执行任务，其可以于play全局或者某任务中，此外，甚至可以在sudo时使用sudo_user 指定sudo时切换的用户1234567- hosts: webnodes remote_user: bds tasks: - name: test connection ping: remote_user: bds sudo: yes 任务列表和action play的主体部分是task list task list中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后在开始第二个任务，在运行自上而下某个playbook时，如果中途发生错误，所有已经执行的任务都会讲回滚，因此，在更正playbook后重新执行一次即可 task目的是使用指定的参数执行模块，而在模块参数中可以使用变量，模块执行是具有幂等性的，这意味着多次执行是安全的，因为其结构均一致 每个task都应该有其name ，用于playbook执行结果输出，建议其内容尽可能清晰地描述任务执行步骤，如果未提供name，则action的结果将用于输出 定义task的可以使用“action： module option”或者module: options 推荐使用后者以实现向后兼容，如果action 一行的内容过多，也可以使用在行首使用几个空白字符进行换行。 123tasks:- name: make sure apache is running service: name=httpd state=running 在众多模块中，只用command和shell模块仅需要给定一个列表而无需使用“key=value”格式例如 123tasks:- name: disable selinux shell: /sbin/setenforce 0 如果命令或者脚本的退出码不为零，可以使用如下的方式替代 123tasks:- name: run this command and igonre the result shell: /usr/bin/somecomand || /bin/true 或者使用ignore_errors来忽略错误信息 1234tasks:- name: run this command and ignore the result shell: /usr/bin/somecommand ingore_errors: True 写一个示例: 123456[root@bj-idc-15 playbooks]# cat /etc/ansible/hosts #现在hosts配置,新添加一台主机[web]192.168.122.52[db]10.10.10.1510.10.10.14 1234567891011121314[root@bj-idc-15 playbooks]# cat nginx.yml---- hosts: web remote_user: root tasks: - name: create nginx group group: name=nginx system=yes gid=208 - name: create nginx user user: name=nginx system=yes uid=208 group=nginx- hosts: db remote_user: root tasks: - name: copy file to dbservers copy: src=/etc/inittabdest=/tmp/inittale.ansible 执行结果 handlers用于当关注的资源发生变化时采取一定的操作,notify 这个action可用于在每个play的最后被触发，这样可以避免多次有改变发生的时候每次都执行指定的操作,取而代之,仅在所有的变化发生完成时最后一次性的执行指定的操作,在notify中列出的操作成为handlers,也即为notify中调用handler中定义的操作 12345- name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: - restart memcached - restart apache handler是task列表，这些task与前述的task并没有本质上的区别 12345handlers:- name: restart memcached #名字要和上面notify的 一致 service: name=memcached state=restarted- name: restart apache service: name=apache state=restarted 简单案例: 没有handler的时候1234567891011[root@bj-idc-14 playbooks]# cat apache.yml---- hosts: web remote_user: root tasks: - name: install httpd package yum: name=httpd state=latest - name: install configurest file copy: src=conf/httpd.conf dest=/etc/httpd/conf/httpd.conf - name: start httpd service service: name=httpd enabled=true state=started 简单案例： 当有一个需求，需要改变httpd配置文案的时候，那么这个时候是需要重启httpd服务的，这时候就需要handlers了，只有某个条件满足的时候才执行12345678910111213141516[root@bj-idc-14 playbooks]# cat apache.yml---- hosts: web remote_user: root tasks: - name: install httpd package yum: name=httpd state=latest - name: install configurest file copy: src=conf/httpd.conf dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service service: name=httpd enabled=true state=startedhandlers: - name: restart httpd service: name=httpd state=restarted Templates模板如果说俩个webservser 安装httpd node1监听80端口，node2 监听8080端口，node1使用的maxClient=100 node2的maxClient=200，这样就需要俩个配置，非常不方便，这样就可以尝试用变量的方式来解决 简单案例: 模板中定义变量12345[root@bj-idc-14 playbooks]# cat templates/httpd.conf.j2 | grep &#123;&#123; #httpd.conf.j2就是httpd的配置文件MaxClients &#123;&#123; maxclient &#125;&#125;MaxClients &#123;&#123; maxclient &#125;&#125;Listen &#123;&#123; http_port &#125;&#125;ServerName &#123;&#123; ansible_fqdn &#125;&#125; # facts 变量 123456789101112131415161718192021[root@bj-idc-14 playbooks]# cat apache.yml---- hosts: web remote_user: root vars: - http_port: 888 #定义的变量值 ,然后查看主机的配置文件是否为这里的值 - maxclient: 305 #定义的变量值 ,然后查看主机的配置文件是否为这里的值 tasks: - name: install httpd package yum: name=httpd state=latest - name: install configurest file copy: src=conf/httpd.conf dest=/etc/httpd/conf/httpd.conf #把带变量的模板替换正在运行的配置文件,然后通知httpd重启加载新的配置文件 template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service service: name=httpd enabled=true state=startedhandlers: - name: restart httpd service: name=httpd state=restarted 执行结果1234567[root@bj-idc-14 playbooks]# cat /etc/httpd/conf/httpd.conf |grep -v &quot;^#&quot;| grep ServerNameServerName bj-idc-14[root@bj-idc-14 playbooks]# cat /etc/httpd/conf/httpd.conf |grep -v &quot;^#&quot;| grep ListenListen 888[root@bj-idc-14 playbooks]# cat /etc/httpd/conf/httpd.conf |grep -v &quot;^#&quot;| grep MaxClientsMaxClients 305MaxClients 305 ansible-playbook 中yaml基础元素 变量 Invertory 条件判断 迭代机制 变量 变量命名变量名仅能有字母，数字和下划线组成，且只能以字母开头 factsfacts是由正在通信的远程目标主机发回的信息，可以直接引用, 这些信息保存在ansible变量中，要获取指定的远程主机所支持的所有facts，可试用如下命令进行ansible hostname -m setup register把任务的输出定义为变量,然后用于其他任务,示例如下: 1234tasks:shell: /usr/bin/fooregister: foo_resultignore_error: True 通过命令传递变量在运行playbook的时候,也可以传递一些变量供playbook使用,示例如下 1ansible-playbook test.yaml –extra-vars “hosts=wwwuser=bds” 通过roles传递变量当给一个主应用角色的时候可以传递变量,然后在角色内使用这变量,如下 1234- host: webservers roles: - commn - &#123; role: foo_arpp_instance , dir: ‘web/htdocs/a.com’ , port: 8080 &#125; 变量实战vars的简单案例 123456789101112[root@bj-idc-14 playbooks]# cat http.yml---- hosts: web remote_user: root vars: - groupuser: httpd - username: httpd tasks: - name: create &#123;&#123; groupuser &#125;&#125; group group: name=&#123;&#123; groupuser &#125;&#125; system=yes gid=238 - name: create &#123;&#123; username &#125;&#125; user user:name=&#123;&#123; username &#125;&#125; system=yes uid=238 group=&#123;&#123; groupuser &#125;&#125; 执行结果 facts的简单案例: 定义主机变量 12345[root@bj-idc-14 ansible]# cat hosts[web]10.10.10.14 httpvars=&apos;10.10.10.14&apos;[db]10.10.10.15 12345678[root@bj-idc-14 playbooks]# cat facts_host.yml---- hosts: web remote_user: root tasks: - name: copy file copy: content=&quot;&#123;&#123; ansible_all_ipv4_addresses &#125;&#125;, &#123;&#123; httpvars &#125;&#125; , &#123;&#123; ansible_cmdline.LANG &#125;&#125; &quot; dest=/tmp/vars.ansible 1[root@bj-idc-14 playbooks]# ansible-playbook facts_host.yml 执行结果 Inventoryansible的主要功能用在于批量操作主机，为了便捷的使用其中的部分主机，可以在Inventory file中将其分组命名，默认的Inventory file为/etc/ansible/hostsInventory file 可以有多个也可以通过DynamicInvertory 来动态生成 Inventory文件格式Inventory文件遵循INI文件风格，中括号中的字符为组名，可以将同一个主机同时归并到多个不同的组中，此外，当如若目标主机使用了非默认的ssh端口，还可以在主机名称之后使用冒号加端口来表明例子:1234567ntp.bds.com[webservers]www1.bds.comwww2.bds.com[bdservers]db1.bds.comdb2.bds.com 如果主机名称遵循相识的命名模式，还可以使用列表的形式标识各主机例子：1234[webservers]www[0-51].bds.com[dbservers]db-[a-f].bds.com 主机变量可以再Inverntory中定义主机时，为其添加主机变量，以便于在playbook中使用例子:12[webservers]www1.bds.com http_port=80 maxRequestsPerChild=1024 组变量组变量是指赋予给指定的组内所有的主机上的在playbook中可用的变量例子:123456[webservers] #可以调用下面[webservsers:vars]中的变量www1.bds.comwww2.bds.com[webservsers:vars]ntp_servser=ntp.bds.comnfs_servser=nfs.bds.com 组嵌套Inventory中，组还可以包含其他的组，并且也可以向组中的主机指定变量，不过，这些变量只能在ansible-playbook中使用，而ansible不支持例子:1234567891011[apache]http1.bds.comhttp2.bds.com[nginx]ngx1.bds.comngx2.bds.com[webservsers:children]apachenginx[webservsers:vars]ntp_server=ntp.bds.com Inventory参数ansible 基于ssh连接Invertory中指定的远程主机时，还可以通过参数指定其交互方式，这些参数如下所示12345678基本结构-host: webremote_user: roottasks: - task1 modulesname: module_args- task2 - host: dbserver 条件测试如果需要根据变量，facts或者此前任务的执行结果来作为某个tasks执行与否的前提时要用到的条件测试 when语句在task后添加when子句即可使用条件测试，when语句支持Jinjia2表达式语法，例如 1234tasks: - name: &quot;shutdown Debian falovred systems&quot; command: /sbin/shutdown -h now when: ansible_os_family == &quot;Debian&quot; when语句中可以使用Jinja2的大多filter功能，例如要忽略此前某语句的错误并基于其结果(failed或者sccess)运行后面指定的语句，可使用类似如下形式 12345678910tasks:- command: /bin/false register: result ignore_errors: True- command: /bin/something when: result| failed- command: /bin/something_else when: result|success- command: /bin/still/something_else when: result| skipped 此外when语句还可以使用facts或者playbooks中定义的变量 简单案例 123456789101112[root@bj-idc-14 playbooks]# ansible web -m setup |grep fqdn&quot;ansible_fqdn&quot;: &quot;bj-idc-14&quot;,[root@bj-idc-14 playbooks]# cat when.yml ---- hosts: web remote_user: root vars: - username: user10 tasks:- name: create &#123;&#123; username &#125;&#125;user user: name=&#123;&#123; username &#125;&#125; uid=510 when: ansible_fqdn == &quot;bj-idc-14&quot; 执行结果 迭代机制当有需要重复性的执行的任务的时候，可以使用迭代机制，其使用格式为将需要迭代的内容定义为item变量引用，并通过with_items 语句来指定迭代的元素列表即可例如： 12345- name: add serveral users user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel with_items: - testuser1 - testuser2 上面的语句等同于下面的语句 1234- name: add serveral users1 user: name=testuser1 state=present groups=wheel - name: add serveral users2 user: name=testuser1 state=present groups=wheel 事实上，with_items中可以使用元素还可以为hashes，例如 12345- name: add serveral users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups&#125;&#125; with_items: - &#123; name: &apos;testuser1&apos;, groups: &apos;wheel&apos; &#125; - &#123; name: &apos;testuser2&apos;, gorups: &apos;wheel&apos; &#125; ansible的循环机制还有很多高级功能,具体参见官方文档迭代: 表示重复同类task时使用 12345调用: item 定义循环列表: with_items - apache - php - mysql 注意: with_items中的列表值可以是字典，但是引用的时候是使用item.KEY 123- &#123;name: apache, conf: conffiles/httpd.conf &#125; - &#123;name: php , conf: conffiles/php.ini &#125; - &#123;name: mysql-servser, conf: conffiles/my.conf ansible-playbook 小技巧Tags tags用于让用户选择运行或者路过playbook中的部分代码 ansible具有幂等性，因此会自身跳过没有变化的部分 即便如此,有些代码为测试其确实没有发生变化的时间依然会非常的地长,此时,如果确实其没有发生变化,就可以通过tags跳过这些代码片段当改变配置文件的时候 对于安装软件的操作就不需要在执行了,这时候有了tags就可以标记你期望运行的task任务中 tags表示在playbook可以为某个任务或者某些任务定义一个标签 在执行次playbook时候通过为ansible-playbook 命令使用—tags选项能实现仅仅运行指定的tasks而非所有的 简单案例 123456789101112131415161718192021222324[root@bj-idc-14 playbooks]# cat apache.yml --- - hosts: web remote_user: root vars: - http_port: 888 - maxclient: 305 tasks: - name: install httpd package yum: name=httpd state=latest - name: install configurest file #copy: src=conf/httpd.conf dest=/etc/httpd/conf/httpd.conf template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf tags: - config #定义了一个tags 叫做config notify: - restart httpd - name: start httpd service service: name=httpd enabled=true state=started tags: - always #tags特殊用法 代表总是执行这个任务handlers: - name: restart httpd service: name=httpd state=restarted 执行结果 check检测和语法检测不要做任何改变，相反，试着预测一些可能发生的变化 语法检测 list列出 forks线程语法: -f FORKS, —forks=FORKS step交互执行 ansible-playbook 角色roles 定义roles使用ansible自1.2版本引入的新特性，用于层次性，结构性的组织playbook，roles能够根据层次型结构自动装载变量文件，tasks以及hanlders等 要使用roles只需要在playbook中使用include指令即可 简单来讲，roles就是通过分别将变量，文件，任务，模块以及处理器位置放置于单独的目录中，并可以便捷地include他们的一种机制，角色一般用于基于主机机构建服务的场景中 但也可以用于构建守护进程等场景中 一个roles的案例如下所示 123456789101112131415161718site.ymlwebservers.ymlfooservers.ymlroles/ common/ files/ templates/ tasks/ handlers/ vars/ meta/ webservsers/ files/ templates/ tasks/ handlers/ vars/ meta/ 在playbook中，可以这样使用roles 12345---- hosts: webservers roles: - common - webservers 也可以向roles传递参数 12345---- hosts: webservsers roles: - common - &#123; role: foo_app_instance，dir: &apos;/opt/a&apos; port: 5000 &#125; 甚至可以条件式的使用roles 1234---- hosts: webservers roles: - &#123; roles: some_role, when: &quot;ansible_os_family == &apos;Redhat&apos; &quot;&#125; 还可以role之间设定依赖关系 roles创建步骤 创建以roles命名的目录 在roles目录中分别创建以各个角色命名的目录， 如webservers等 在每个角色命名的目录中分别创建files，handles，meta，tasks，templates，和vars等目录，用不到的可以创建为空目录，也可以不创建 在playbook文件中，调用各个角色 roles内各个目录中可用的文件 tasks目录: 至少应该包含一个名为main.yml的文件，其定义了此角色的任务列表，此文件可以使用include包含其他的位于此目录中的task文件 files目录: 存放由copy 和script等模块调用的文件 templates目录: template模块会自动再次目录中寻找Jinja2模板文件 handlers目录: 此目录中应当包含一个main.yml文件，用于定义此角色用到的各handler：在handler中使用include包含的其它的handler文件也应该位于此目录中 vars目录: 应当包含一个main.yml文件，用于定义此角色用到的变量 meta目录: 应当包含一个main.yml文件， 用于定义此角色的特殊设定的依赖关系， ansible 1.3及以后的版本才支持 default目录： 为当前角色设定默认变量时使用的目录，应当包含一个main.yml文件 roles总结 目录名同为角色名 目录结构有固定格式 files：静态文件 templates： Jinja2 模板文件 tasks：至少有一个main.yml文件，定义各tasks handlers： 至少有一个main.yml文件，定义各handlers vars：定义变量 meta：定义依赖关系信息 site.yml中定义playbook， 额外也可以有其他的yml文件 roles简单案例 建立目录 1[root@bj-idc-14 playbooks]# mkdir -pv /root/ansible_playbooks/roles/&#123;websrvs,dbsrvs&#125;/&#123;tasks,files,templates,meta,handlers,vars&#125; 查看目录树 1234567891011121314151617[root@bj-idc-14 playbooks]# tree /root/ansible_playbooks//root/ansible_playbooks/└── roles├── dbsrvs│ ├── files│ ├── handlers│ ├── meta│ ├── tasks│ ├── templates│ └── vars└── websrvs├── files├── handlers├── meta├── tasks├── templates└── vars 12345678910[root@bj-idc-14 ansible_playbooks]# cat site.yml---- hosts: web remote_user: root roles:- websrvs- hosts: web remote_user: root roles:- dbsrvs 目录树 执行结果第一次websrvs 第二次websrvs和dbsrvs]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tengine-lua_install]]></title>
    <url>%2F2017%2F09%2F07%2Ftengine_lua_install%2F</url>
    <content type="text"><![CDATA[shell 脚本安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#!/bin/bashif [ ! -e /Data/apps ];then mkdir /Data/apps -pv fiif [ ! -e /opt/src ];then mkdir /opt/srcficd /opt/src#tengineif [ ! -e /opt/src/tengine-2.2.0.tar.gz ];then wget http://tengine.taobao.org/download/tengine-2.2.0.tar.gz tar xf tengine-2.2.0.tar.gzfi#ngx_purgeif [ ! -e /opt/src/ngx_cache_purge-2.3.tar.gz ];then wget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gz tar xf ngx_cache_purge-2.3.tar.gzfi#ngx_devel_kitif [ ! -e /opt/src/v0.3.0rc1.tar.gz ];then wget https://github.com/simpl/ngx_devel_kit/archive/v0.3.0rc1.tar.gz tar xf v0.3.0rc1.tar.gzfi#luajitif [ ! -e /opt/src/LuaJIT-2.0.4.tar.gz ];then wget http://luajit.org/download/LuaJIT-2.0.4.tar.gz tar xf LuaJIT-2.0.4.tar.gzfi#lua-nginx-moduleif [ ! -e /opt/src/v0.10.2.tar.gz ];then wget https://github.com/openresty/lua-nginx-module/archive/v0.10.2.tar.gz tar xf v0.10.2.tar.gzfiif [ ! -e /Data/apps/luajit ];then cd LuaJIT-2.0.4 make make install PREFIX=/Data/apps/luajitfiif [ ! -e /etc/profile.d/luajit.sh ];thencat &gt; /etc/profile.d/luajit.sh &lt;&lt;EOFexport LUAJIT_LIB=/Data/apps/luajit/libexport LUAJIT_INC=/Data/apps/luajit/include/luajit-2.0/EOFfitest -e /etc/profile.d/luajit.sh &amp;&amp; . /etc/profile.d/luajit.shtest -e /Data/apps/luajit/lib/libluajit-5.1.so.2 &amp;&amp; ln -s /Data/apps/luajit/lib/libluajit-5.1.so.2 /lib64/#nginxcd /opt/src/tengine-2.2.0./configure --prefix=/Data/apps/nginx/ --with-debug --add-module=/opt/src/ngx_cache_purge-2.3 --with-http_stub_status_module --with-http_ssl_module --add-module=/opt/src/ngx_devel_kit-0.3.0rc1 --add-module=/opt/src/lua-nginx-module-0.10.2/ --with-ld-opt=-Wl,-rpath,/Data/apps/luajit/libmakemake install[ $? -eq 0 ] &amp;&amp; echo &apos;The tengine lua update Success&apos; nginx配置文件server 主机配置12345location /lua &#123; # MIME type determined by default_type: default_type &apos;text/plain&apos;; content_by_lua &quot;ngx.say(&apos;Hello World Lua!&apos;)&quot;;&#125; web页面访问 fpm打包目录结构1/tmp/nginxinstall/Data/apps/nginx 脚本12345678[root@budongshu]# cat /tmp/pro.sh #!/bin/bashif [ `id avatar |grep avatar | wc -l` -eq 1 ]; then exit 0else useradd avatar exit 0fi 12345678[root@budongshu]# cat /tmp/post.sh #!/bin/bashif [ -e /Data/apps/nginx ] ;then rm -fr /Data/apps/nginx exit 0else exit 0fi 命令安装1/usr/local/bin/fpm -s dir -t rpm -n hdf-tengine -v 2.2.0 --iteration 3.el6 -d &apos;pcre,pcre-devel,openssl-devel&apos; --post-install /tmp/pro.sh --post-uninstall /tmp/post.sh -f -C /tmp/nginxinstall/ --description &apos;proxy tengine lua 2.2.0 rpm&apos; -p /opt/]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https_openssl_update]]></title>
    <url>%2F2017%2F09%2F07%2Fhttps_openssl_update%2F</url>
    <content type="text"><![CDATA[升级opensslhttps 网站打分https://www.ssllabs.com/ssltest/analyze.html?d=www.jd.com openssl 漏洞查询https://blog.myssl.com/https-security-best-practices-2/1234567891011121314mkdir /Data/appscd /optwget https://www.openssl.org/source/old/1.0.1/openssl-1.0.1t.tar.gztar xf openssl-1.0.1t.tar.gzcd openssl-1.0.1t./config shared zlib --prefix=/Data/apps/opensslmakemake installmv /usr/bin/openssl /usr/bin/openssl.oldmv /usr/include/openssl /usr/include/openssl.oldln -s /Data/apps/openssl/bin/openssl /usr/bin/opensslln -s /Data/apps/openssl/include/openssl /usr/include/openssl ln -s /Data/apps/openssl/lib/libssl.so.1.1 /usr/lib64/libssl.so.1.1ln -s /Data/apps/openssl/lib/libcrypto.so.1.1 /usr/lib64/libcrypto.so.1.1 1openssl version 重新编译nginx查看nginx 是否静态编译openssl1 nginx -V 发现没有显示出来build openssl 的版本 则表明是静态编译的2 ldd /Data/apps/nginx/sbin/nginx1234567891011121314[root@l-ng5.ops.prod.idc1 openssl]# ldd /Data/apps/nginx/sbin/nginx linux-vdso.so.1 =&gt; (0x00007ffd70ac8000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x0000003014c00000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x0000003014400000) libcrypt.so.1 =&gt; /lib64/libcrypt.so.1 (0x0000003016400000) libluajit-5.1.so.2 =&gt; /Data/apps/luajit/lib/libluajit-5.1.so.2 (0x00007f78bd38f000) libm.so.6 =&gt; /lib64/libm.so.6 (0x0000003015400000) libpcre.so.0 =&gt; /lib64/libpcre.so.0 (0x00007f78bd162000) libz.so.1 =&gt; /lib64/libz.so.1 (0x0000003015800000) libc.so.6 =&gt; /lib64/libc.so.6 (0x0000003014800000) /lib64/ld-linux-x86-64.so.2 (0x0000003014000000) libfreebl3.so =&gt; /lib64/libfreebl3.so (0x0000003018800000) libgcc_s.so.1 =&gt; /lib64/libgcc_s.so.1 (0x0000003c8ea00000)# 如果依赖库不含有Openssl，则表明是静态编译的Openssl的。 修改下载解压后nginx源码目录里面代码进入目录12cd /opt/src/tengine-2.2.0/auto/lib/openssl cat conf 找到下面这样一段代码1234CORE_INCS=&quot;$CORE_INCS $OPENSSL/.openssl/include&quot;CORE_DEPS=&quot;$CORE_DEPS $OPENSSL/.openssl/include/openssl/ssl.h&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/.openssl/lib/libssl.a&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/.openssl/lib/libcrypto.a&quot; 更改成 1234CORE_INCS=&quot;$CORE_INCS $OPENSSL/include&quot;CORE_DEPS=&quot;$CORE_DEPS $OPENSSL/include/openssl/ssl.h&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/lib/ssleay32.lib&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/lib/libeay32.lib&quot; nginx 编译参数1./configure --prefix=/Data/apps/nginx/ --with-debug --add-module=/opt/src/ngx_cache_purge-2.3 --with-http_stub_status_module --with-http_ssl_module --add-module=/opt/src/ngx_devel_kit-0.3.0rc1 --add-module=/opt/src/lua-nginx-module-0.10.2/ --with-ld-opt=-Wl,-rpath,/Data/apps/luajit/lib --with-openssl=/Data/apps/openssl]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible 基础模块介绍]]></title>
    <url>%2F2017%2F09%2F06%2Fansible_module%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9D%97%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[运维自动化工具介绍 在日常服务器维护中，从系统安装到程序部署再到发布应用，在大规模的生产环境中，如果需要手动的每台服务器进行安装配置将会给运维人员带来许多繁琐而又重复的工作。这就促使了在每个运维层次中出现了不同的自动化运维工具。常见的自动化运维工具分类有以下几类： 系统安装运维工具（OS Provisioning）： 常见的有：PXE,Cobbler，Red Hat Satelite(redhat)系统专用等 操作系统的配置运维工具(OS Config)： 常见的有：cfengine，puppet,saltsack,chef等 应用程序部署工具(Application Service Orchestration): 常见的有:Func,Fabric,ControITier,Capistrano等 根据工作模式不同上面的运维工具有分为以下两类： agent：基于ssl协议实现，agent工作在被监控端，例如：puppet agentless: 基于ssh key实现，例如：ansible ansible介绍 ansible是一款轻量级自动化运维工具，由Python语言开发，结合了多种自动化运维工具的特性，实现了批量系统配置、批量程序部署、批量命令执行等功能；ansible是基于模块化实现批量操作的。 ansible组成 Ansible： 核心 Modules： 包括 Ansible 自带的核心模块及自定义模块 Plugins： 完成模块功能的补充，包括连接插件、邮件插件等 Playbooks： 网上很多翻译为剧本，个人觉得理解为编排更为合理；定义 Ansible 多任务配置文件，有 Ansible 自动执行 Inventory： 定义 Ansible 管理主机的清单 ansible特点模块化、部署简单、工作于agentless模式、默认使用ssh协议、支持自定义模块、支持Palybook等 ansible 基本安装介绍系统环境1234[root@note1 ~]# uname -aLinux note1 2.6.32-504.el6.x86_64 #1 SMP Wed Oct 15 04:27:16 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux[root@note1 ~]# cat /etc/redhat-release CentOS release 6.6 (Final) epel源12345wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repo``` ### 安装ansible```python[root@note1 ~]# yum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto ansible 配置ansible主机文件1234567[root@note1 ~]# &gt; /etc/ansible/hosts #清空文件(操作前先备份)[root@note1 ~]# vim /etc/ansible/hosts #编辑配置主机文件[root@note1 ~]# cat /etc/ansible/hosts #查看配置[web]192.168.70.51[db]192.168.70.50 配置主机免密钥登陆为了避免Ansible下发指令时输入目标主机密码，通过证书签名达到SSH无密码是一个好的方案，推荐使用ssh-keygen与ssh- copy-id来实现快速证书的生成和公钥下发，其中ssh-keygen生成一对密钥，使用ssh-copy-id来下发生成的公钥。具体操作如下： 123456789101112131415161718[root@note1 ~]ssh-keygen -t rsa -P ''Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:a8:eb:cc:da:26:06:67:9b:23:ae:45:04:d4:76:63:bb root@bj-idc-15The key's randomart image is:+--[ RSA 2048]----+|o.. || . o + || o o o || . . . || . o S ||..o E || +.o. ||..*+.. ||++.** | 密钥拷贝到远程主机12345678910111213[root@note1 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.70.51root@192.168.70.51's password: Now try logging into the machine, with "ssh 'root@10.10.10.14'", and check in: .ssh/authorized_keysto make sure we haven't added extra keys that you weren't expecting.[root@note1 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.70.50root@192.168.70.50's password: Now try logging into the machine, with "ssh 'root@192.168.70.50'", and check in: .ssh/authorized_keysto make sure we haven't added extra keys that you weren't expecting.*注意：在首次连接或者重装系统之后会出现检查 keys 的提示* 测试ping12345678910111213141516171819202122[root@note1 ~]# ansible all -m ping The authenticity of host '192.168.70.50 (192.168.70.50)' can't be established.RSA key fingerprint is 56:49:f5:4f:3e:30:8d:5c:2c:42:06:79:69:a4:18:89.Are you sure you want to continue connecting (yes/no)?解决办法:vim /etc/ansible/ansible.cfg 或者 ~/.ansible.cfg[defaults]host_key_checking = False也可以通过设置系统环境变量来禁止这样的提示export ANSIBLE_HOST_KEY_CHECKING=False应用最后一个办法[root@note1 ~]# export ANSIBLE_HOST_KEY_CHECKING=False再次测试[root@note1 ~]# ansible all -m ping 192.168.70.50 | success &gt;&gt; &#123; "changed": false, "ping": "pong"&#125;192.168.70.51 | success &gt;&gt; &#123; "changed": false, "ping": "pong"&#125; Ansible命令参数介绍1234567891011-v,–verbose 详细模式，如果命令执行成功，输出详细的结果(-vv –vvv -vvvv)-i PATH,–inventory=PATH 指定host文件的路径，默认是在/etc/ansible/hosts -f NUM,–forks=NU NUM是指定一个整数，默认是5，指定fork开启同步进程的个数。 -m NAME,–module-name=NAME 指定使用的module名称，默认是command-m DIRECTORY,–module-path=DIRECTORY 指定module的目录来加载module，默认是/usr/share/ansible, -a,MODULE_ARGS 指定module模块的参数 -k,-ask-pass 提示输入ssh的密码，而不是使用基于ssh的密钥认证-sudo 指定使用sudo获得root权限-K,-ask-sudo-pass 提示输入sudo密码，与–sudo一起使用 -u USERNAME,-user=USERNAME 指定移动端的执行用户 -C,-check 测试此命令执行会改变什么内容，不会真正的去执行 主机清单介绍hosts Ansible 通过读取默认的主机清单配置/etc/ansible/hosts，可以同时连接到多个远程主机上执行任务，默认路径可以通过修改 ansible.cfg 的 hostfile 参数指定路径。 12345678[dbserver] []表示主机的分组名,可以按照功能,系统进行分类,便于进行操作192.168.10.2 one.example.com www.bds.com:5309 #支持指定ssh端口5309 jumper ansible_ssh_port=5309 ansible_ssh_host=192.168.10.2 #设置主机别名为jumperwww[01:50].bds.com #支持通配符匹配www01.bds.com www02.bds.com[web] #提醒下这里面字母是随便定义的web-[a:f].bds.com #支持字母匹配 web-a.bds.com ..web-f.bds.com 为主机指定类型和连接用户12345[bds]Localhost ansible_connection=localother1.example.com ansible_connection=ssh ansible_ssh_user=deployother2.example.com ansible_connection=ssh ansible_ssh_user=deployansible hosts配置文件中支持指令 注意: 前面如果不配置主机免密钥登录,可以在/etc/ansible/hosts中定义用户和密码,主机ip地址,和ssh端口,这样也可以进行免密码访问,但是这个/hosts文件要保护好,因为所有的密码都写在里面 hosts文件配置参数介绍 1, ansiblessh_host :指定主机别名对应的真实 IP，如：100 ansible_ssh_host=192.168.1.100，随后连接该主机无须指定完整 IP，只需指定 251 就行2, ansible_ssh_port :指定连接到这个主机的 ssh 端口，默认 223, ansible_ssh_user:连接到该主机的 ssh 用户4, ansible_ssh_pass:连接到该主机的 ssh 密码（连-k 选项都省了），安全考虑还是建议使用私钥或在命令行指定-k 选项输入5, ansible_sudo_pass: sudo 密码6, ansible_sudo_exe: sudo 命令路径7, ansible_connection :连接类型，可以是 local、ssh 或 paramiko，ansible1.2 之前默认为 paramiko8, ansible_ssh_private_key_file : 私钥文件路径9, ansible_shell_type :目标系统的 shell 类型，默认为 sh,如果设置 csh/fish，那么命令需要遵循它们语法10, ansible_python_interpreter :python 解释器路径，默认是/usr/bin/python，但是如要要连*BSD系统的话，就需要该指令修改 python 路径11, ansible_interpreter :这里的”“可以是 ruby 或 perl 或其他语言的解释器，作用和 ansible_python_interpreter 类似 ansible 常用模块介绍ansible使用帮助12[root@note1 ~]# ansible-doc -l #查询ansible的所有模块[root@note1 ~]# ansible-doc -s module_name #查看模块的属性信息 例子: 查询service 模块的信息123456789101112131415161718[root@note1 ~]# ansible-doc -s service less 436Copyright (C) 1984-2009 Mark Nudelmanless comes with NO WARRANTY, to the extent permitted by law.For information about the terms of redistribution,see the file named README in the less distribution.Homepage: http://www.greenwoodsoftware.com/less- name: M a n a g e s e r v i c e s . action: service arguments # Additional arguments provided on the command line enabled # Whether the service should start on boot. *At least one of state and enabled are requi name= # Name of the service. pattern # If the service does not respond to the status command, name a substring to look for as runlevel # For OpenRC init scripts (ex: Gentoo) only. The runlevel that this service belongs to. sleep # If the service is being `restarted' then sleep this many seconds between the stop and state # `started'/`stopped' are idempotent actions that will not run commands unless necessary(END) ansible语法 ansible -m -a command模块 默认模块 ,用于在各个被管理节点运行指定的命令(不支持管道和变量) 12345[root@note1 ~]# ansible all -m command -a "hostname "192.168.70.51 | success | rc=0 &gt;&gt;bds192.168.70.50 | success | rc=0 &gt;&gt;note1 shell模块command模块功能相同，但比command的模块功能强大(支持管道和变量) 1234567[root@note1 ~]# ansible all -m shell -a "cat /etc/passwd| grep root " 192.168.70.51 | success | rc=0 &gt;&gt;root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin192.168.70.50 | success | rc=0 &gt;&gt;root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin user模块 用户模块,用于在各管理节点管理用户所使用创建一个名字为DBA的用户,uid是505 ,家目录是/Data/dba,shell是不让用户登录 12345678910111213[root@note1 ~]# ansible db -m user -a 'name=DBA uid=505 home=/Data/dba shell=/sbin/nologin' 192.168.70.50 | success &gt;&gt; &#123; "changed": true, "comment": "", "createhome": true, "group": 505, "home": "/Data/dba", "name": "DBA", "shell": "/sbin/nologin", "state": "present", "system": false, "uid": 505&#125; 删除一个用户 1ansible db -m user -a 'name=budongshu uid=506 state=absent' group模块1ansible db -m group -a 'name=test gid=1000' cron模块计划定时任务,用于在各管理节点管理计划任务 1[root@note1 ~]# ansible all -m cron -a "name=time minute='*/2' job='/usr/sbin/ntpdate copy模块复制模块,复制文件到各个节点 1[root@note1 ~]# ansible all -m copy -a "src=/etc/hosts dest=/tmp/ mode=600" file模块 文件模块 , 修改各个节点指定的文件属性 1[root@note1 ~]# ansible all -m file -a 'path=/tmp/hosts mode=644 owner=DBA' 创建目录类似mkdir –p 12[root@note1 ~]# ansible all -m file -a "dest=/tmp/ansible.txt mode=755 owner=root group=root state=directory" file删除文件或者目录 1[root@note1 ~]# ansible all -m file -a "dest=/tmp/ansible.txt state=absent" 注：state的其他选项：link(链接)、hard(硬链接) stat 模块 获取远程文件状态信息，包含atime、ctime、mtime、md5、uid、gid等 1[root@note1 ~]# ansible all -m stat -a "path=/etc/passwd " ping 模块 测试模块 ,测试各个节点是否正常在线 1ansible all -m stat -a 'path=/etc/passwd' template模块 根据官方的翻译是：template使用了Jinjia2格式作为文件模板，进行文档内变量的替换的模块。他的每次使用都会被ansible标记为changed状态。 yum模块 用于管理节点安装软件所使用 123456789101112131415161718192021[root@note1 ~]# ansible all -m yum -a 'name=ntp state=present'卸载的软件只需要将 name=ntp state=absent 安装特定版本 name=nginx-1.6.2 state=present指定某个源仓库安装软件包name=htop enablerepo=epel state=present更新软件到最新版 name=nginx state=latest``` ### service模块 管理各个节点的服务```python[root@note1 ~]# ansible all -m service -a "name=ntpd enabled=true state=started" state 支持其它选项 started stopped restarted ``` ### script模块 自动复制脚本到远程节点,并运行* 测试脚本```python[root@note1 ~]# cat ansible_test.sh #!/bin/bash echo "hello world " &gt;&gt; /tmp/ansible_sh.log 运行脚本1[root@note1 ~]# ansible all -m script -a 'ansible_test.sh' setup模块 收集ansible的facts信息 1[root@note1 ~]# ansible all -m setup #收集主机的facts信息,可以通过变量引用这些信息 ansible 主机清单通配模式介绍 可以看到上面执行命令的时候有个ansible -m all ,以上我用的all或指定主机,这里也可以进行通配 ,在/etc/ansible/hosts 进行设置如下 12345678[web]10.10.10.210.10.10.3[db]10.10.10.4 [allhost:children] #可以把一个组当做另一个组的子成员webdb 例子:12ansible web -m shell -a ‘uptime’ #代表web组中的所有主机ansible allhost -m shell -a ‘uptime’ #代表allhost组中的所有子成员组 其它匹配方式1.1 通配所有主机all , ansible all -m shell -a ‘uptime’ansible -m shell –a ‘uptime’ 1.2 通配具有规则特征的主机或者主机名one.bds.com.bds.com192.168.10.2192.168.10. 1.3 通配俩组的所有主机,组名之间通过冒号分开,表示or的意思web:db 1.4 非模式匹配: 表示在 web组不在db组的主机web:!db 1.5 交集匹配: 表示同时都在 web 和db组的主机web:&amp;db 1.6 匹配一个组的特定编号的主机 从零开始计算web[0] 1.7 匹配 web组的第 1 个到第 25 个主机web [0-25] 1.8 组合匹配在web组或者在db组中,必须还存在test1组中,但不在test2组中web:db:&amp;test1:!test2 1.9 大部分人都在patterns应用正则表达式,但你可以.只需要以 ‘~’ 开头即可:~(web|db).*.example.com 2.0 同时让我们提前了解一些技能,除了如上,你也可以通过 —limit 标记来添加排除条件,/usr/bin/ansible or /usr/bin/ansible-playbook都支持:ansible-playbook site.yml —limit datacenter2 2.1 如果你想从文件读取hosts,文件名以@为前缀即可.从Ansible 1.2开始支持该功能:ansible-playbook site.yml —limit @retry_hosts.txt]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filebeat Output]]></title>
    <url>%2F2017%2F06%2F11%2Ffilebeat_output%2F</url>
    <content type="text"><![CDATA[Filbeat OutPut Filebeat Elasticsearch OutPut configure 123456789output.elasticsearch: hosts: [&quot;http://localhost:9200&quot;] template.enabled: true template.path: &quot;filebeat.template.json&quot; template.overwrite: false index: &quot;filebeat&quot; ssl.certificate_authorities: [&quot;/etc/pki/root/ca.pem&quot;] ssl.certificate: &quot;/etc/pki/client/cert.pem&quot; ssl.key: &quot;/etc/pki/client/cert.key&quot; 定义ip port add portocalhttps 12345output.elasticsearch: hosts: [&quot;localhost&quot;] protocol: &quot;https&quot; username: &quot;admin&quot; password: &quot;s3cr3t&quot; compression_level gzip 压缩级别 range（1-9） work 发送事件到es的工作数量 index The index name to write events to. The default is “filebeat-%{+yyyy.MM.dd}” (for example,”filebeat-2015.04.26”). indices 支持条件，基于格式字符串的字段访问和名称映射的索引选择器规则的数组 index 要使用的索引格式字符串。 如果使用的字段丢失，则规则失败。 mapping 映射字典为新名字 default 默认字符串数值 when 选择匹配条件 12345678910output.elasticsearch: hosts: [&quot;http://localhost:9200&quot;] index: &quot;logs-%&#123;+yyyy.MM.dd&#125;&quot; indices: - index: &quot;critical-%&#123;+yyyy.MM.dd&#125;&quot; when.contains: message: &quot;CRITICAL&quot; - index: &quot;error-%&#123;+yyyy.MM.dd&#125;&quot; when.contains: message: &quot;ERR&quot; pipeline 格式字符串指定获取节点写入事件pipeline的id值 output.elasticsearch: hosts: [&quot;http://localhost:9200&quot;] pipeline: my_pipeline_id pipelines 123456789101112131415161718filebeat.prospectors:- paths: [&quot;/var/log/app/normal/*.log&quot;] fields: type: &quot;normal&quot;- paths: [&quot;/var/log/app/critical/*.log&quot;] fields: type: &quot;critical&quot;output.elasticsearch: hosts: [&quot;http://localhost:9200&quot;] index: &quot;filebeat-%&#123;+yyyy.MM.dd&#125;&quot; pipelines: - pipeline: critical_pipeline when.equals: type: &quot;critical&quot; - pipeline: normal_pipeline when.equals: type: &quot;normal&quot; template output.elasticsearch: hosts: [&quot;localhost:9200&quot;] template.name: &quot;filebeat&quot; template.path: &quot;filebeat.template.json&quot; template.overwrite: false templates.versions 12345output.elasticsearch: hosts: [&quot;localhost:9200&quot;] template.path: &quot;filebeat.template.json&quot; template.overwrite: false template.versions.2x.path: &quot;filebeat.template-es2x.json max_retries 当发送失败的时候，尝试多少次发送事件 bulk_max_size 单个Elasticsearch批量API索引请求中批量的最大事件数 默认值为50 timeout The http request timeout in seconds for the Elasticsearch request The default is 90 flush_interval 在两个批量API索引请求之间等待新事件的秒数 ssl https://www.elastic.co/guide/en/beats/filebeat/current/configuration-output-ssl.html Filebeat Logstash OutPut 需要logstash服务端安装beat插件 使用lumberjack协议发送事件到logstash 12output.logstash: hosts: [&quot;localhost:5044&quot;] Metadata Fields @meatedata Filebeat使用@metadata字段将元数据发送到Logstash @metadata字段的内容只存在于Logstash中，不属于从Logstash发送的任何事件的一部分 有关@metadata字段的更多信息，请参阅Logstash文档logstash doucument { ... &quot;@metadata&quot;: { &quot;beat&quot;: &quot;filebeat&quot;, &quot;type&quot;: &quot;&lt;event type&gt;&quot; } } logstash to elasticsearch 12345678910111213input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;http://localhost:9200&quot;] index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; &#125;&#125; enabled hosts compression_level worker loadbalance 1234output.logstash: hosts: [&quot;localhost:5044&quot;, &quot;localhost:5045&quot;] loadbalance: true index: filebeat pipelining 异步处理事件，默认关闭 index ssl timeout max_retries bulk_max_size The maximum number of events to bulk in a single Logstash request The default is 2048. kafka OutPut The Kafka output sends the events to Apache Kafka. 123456789101112output.kafka: # initial brokers for reading cluster metadata hosts: [&quot;kafka1:9092&quot;, &quot;kafka2:9092&quot;, &quot;kafka3:9092&quot;] # message topic selection + partitioning topic: &apos;%&#123;[type]&#125;&apos; partition.round_robin: reachable_only: false required_acks: 1 compression: gzip max_message_bytes: 1000000 enabled hosts version username password topic topics topic mapping default when partition random.group_events round_robin.group_events hash.hash hash.random client_id worker codec metadata refresh_frequency retry.max retry.backoff max_retries bulk_max_size timeout broker_timeout channel_buffer_size keep_alive compression max_message_bytes required_acks flush_interval ssl Redis OutPut This output works with Redis 3.2.4. 123456output.redis: hosts: [&quot;localhost&quot;] password: &quot;my_password&quot; key: &quot;filebeat&quot; db: 0 timeout: 5 enabled hosts port index key output.redis: hosts: [&quot;localhost&quot;] key: &quot;%{[fields.list]:fallback}&quot; keys key mapping default when output.redis: hosts: [&quot;localhost&quot;] key: &quot;default_list&quot; keys: - key: &quot;info_list&quot; # send to info_list if `message` field contains INFO when.contains: message: &quot;INFO&quot; - key: &quot;debug_list&quot; # send to debug_list if `message` field contains DEBUG when.contains: message: &quot;DEBUG&quot; - key: &quot;%{[type]}&quot; mapping: &quot;http&quot;: &quot;frontend_list&quot; &quot;nginx&quot;: &quot;frontend_list&quot; &quot;mysql&quot;: &quot;backend_list&quot; passport db datatype 用于发布事件的Redis数据类型。如果数据类型为列表，则使用Redis RPUSH命令，并将所有事件添加到列表中，并在键下定义键。 如果使用数据类型通道，则使用Redis PUBLISH命令，这意味着所有事件都被推送到Redis的pub / sub机制。 通道的名称是键下定义的。 默认值为列表。 codec worker loadbalance timeout max_retries bulk_max_size ssl proxy_url proxy_use_local_resolver File OutPut 文件输出将事务转储到每个事务处于JSON格式的文件中。 目前，该输出用于测试，但可以作为Logstash的输入 12345output.file: path: &quot;/tmp/filebeat&quot; filename: filebeat #rotate_every_kb: 10000 #number_of_files: 7 enables path 定义保存文件的路径 filename 定义保存文件的名字 rotate_every_kb 定义每个文件达到多少kb就开始切割 number_if_files 定义保存几份文件 codec Console OutPut12output.console: pretty: true pretty codec enabled bulk_max_size Codec Output123output.console: codec.json: pretty: true 123output.console: codec.format: string: &apos;%&#123;[@timestamp]&#125; %&#123;[message]&#125;&apos; Loggin OutPut12345678logging.level: warninglogging.to_files: truelogging.to_syslog: falselogging.files: path: /var/log/mybeat name: mybeat.log rotateeverybytes: 10MB keepfiles: 7 DebuggingBy default, Filebeat sends all its output to syslog. When you run Filebeat in the foreground, you can use the -e command line flag to redirect the output to standard error instead. For example: 1filebeat -e The default configuration file is filebeat.yml (the location of the file varies by platform). You can use a different configuration file by specifyingthe -c flag. For example: 1filebeat -e -c myfilebeatconfig.yml You can increase the verbosity of debug messages by enabling one or more debug selectors. For example, to view the published transactions, you can start Filebeat with the publish selector like this: 1filebeat -e -d &quot;publish&quot; If you want all the debugging output (fair warning, it’s quite a lot), you can use *, like this: 1filebeat -e -d &quot;*&quot; supporthttps://www.elastic.co/support/matrix#show_compatibility]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>filebeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filebeat config]]></title>
    <url>%2F2017%2F06%2F11%2Ffilebeat_config%2F</url>
    <content type="text"><![CDATA[Filbeat config Filebeat Prospector12345678910filebeat.prospectors:- input_type: log paths: - /var/log/apache/httpd-*.log document_type: apache- input_type: log paths: - /var/log/messages - /var/log/*.log Filebeat Optionsinput_type: log|stdin 指定输入类型 paths 支持基本的正则，所有golang glob都支持,支持/var/log/*/*.log encoding plain, latin1, utf-8, utf-16be-bom, utf-16be, utf-16le, big5, gb18030, gbk, hz-gb-2312, euc-kr, euc-jp, iso-2022-jp, shift-jis, and so on exclude_lines 支持正则 排除匹配的行，如果有多行，合并成一个单一行来进行过滤 include_lines 支持正则 include_lines执行完毕之后会执行exclude_lines。 exclude_files 支持正则 排除匹配的文件 exclude_files: [‘.gz$’] tags 列表中添加标签，用过过滤 123filebeat.prospectors:- paths: [&quot;/var/log/app/*.json&quot;] tags: [&quot;json&quot;] fields 可选字段，选择额外的字段进行输出 可以是标量值，元组，字典等嵌套类型 默认在sub-dictionary 位置 1234filebeat.prospectors: - paths: [&quot;/var/log/app/*.log&quot;] fields: app_id: query_engine_12 fields_under_root 如果值为ture，那么fields存储在输出文档的顶级位置 如果与filebeat中字段冲突，自定义字段会覆盖其他字段 1234fields_under_root: truefields: instance_id: i-10a64379 region: us-east-1 ignore_older 可以指定Filebeat忽略指定时间段以外修改的日志内容 文件被忽略之前，确保文件不在被读取，必须设置ignore older时间范围大于close_inactive 如果一个文件正在读取时候被设置忽略，它会取得到close_inactive后关闭文件，然后文件被忽略 close_* close_ *配置选项用于在特定标准或时间之后关闭harvester。 关闭harvester意味着关闭文件处理程序。 如果在harvester关闭后文件被更新，则在scan_frequency过后，文件将被重新拾取。 但是，如果在harvester关闭时移动或删除文件，Filebeat将无法再次接收文件，并且harvester未读取的任何数据都将丢失。 close_inactive 启动选项时，如果在制定时间没有被读取，将关闭文件句柄 读取的最后一条日志定义为下一次读取的起始点，而不是基于文件的修改时间 如果关闭的文件发生变化，一个新的harverster将在scan_frequency运行后被启动 建议至少设置一个大于读取日志频率的值，配置多个prospector来实现针对不同更新速度的日志文件 使用内部时间戳机制，来反映记录日志的读取，每次读取到最后一行日志时开始倒计时 使用2h 5m 来表示 close_rename 当选项启动，如果文件被重命名和移动，filebeat关闭文件的处理读取 close_removed 当选项启动，文件被删除时，filebeat关闭文件的处理读取 这个选项启动后，必须启动clean_removed close_eof 适合只写一次日志的文件，然后filebeat关闭文件的处理读取 close_timeout 当选项启动时，filebeat会给每个harvester设置预定义时间，不管这个文件是否被读取，达到设定时间后，将被关闭 close_timeout 不能等于ignore_older,会导致文件更新时，不会被读取 如果output一直没有输出日志事件，这个timeout是不会被启动的，至少要要有一个事件发送，然后haverter将被关闭 设置0 表示不启动 clean_inactived 从注册表文件中删除先前收获的文件的状态 设置必须大于ignore_older+scan_frequency，以确保在文件仍在收集时没有删除任何状态 配置选项有助于减小注册表文件的大小，特别是如果每天都生成大量的新文件 此配置选项也可用于防止在Linux上重用inode的Filebeat问题 clean_removed 启动选项后，如果文件在磁盘上找不到，将从注册表中清除filebeat 如果关闭close removed 必须关闭clean removed scan_frequency prospector检查指定用于收获的路径中的新文件的频率,默认10s document_type 类型事件，被用于设置输出文档的type字段，默认是log harvester_buffer_size 每次harvester读取文件缓冲字节数，默认是16384 max_bytes 对于多行日志信息，很有用，最大字节数 json 这些选项使Filebeat解码日志结构化为JSON消息 逐行进行解码json keys_under_root 设置key为输出文档的顶级目录 overwrite_keys 覆盖其他字段 add_error_key 定一个json_error message_key 指定json 关键建作为过滤和多行设置，与之关联的值必须是string multiline控制filebeat如何处理跨多行日志的选项，多行日志通常发生在java堆栈中 multiline.pattern: &#39;^\[&#39;multiline.negate: truemultiline.match: after 上面匹配是将多行日志所有不是以[符号开头的行合并成一行它可以将下面的多行日志进行合并成一行 12345[beat-logstash-some-name-832-2015.11.28] IndexNotFoundException[no such index] at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:566) at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:133) at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:77) at org.elasticsearch.action.admin.indices.delete.TransportDeleteIndexAction.checkBlock(TransportDeleteIndexAction.java:75) multiline.pattern 指定匹配的正则表达式，filebeat支持的regexp模式与logstash支持的模式有所不同 pattern regexp multiline.negate 定义上面的模式匹配条件的动作是 否定的，默认是false 假如模式匹配条件’^b’，默认是false模式，表示讲按照模式匹配进行匹配 将不是以b开头的日志行进行合并 如果是true，表示将不以b开头的日志行进行合并 multiline.match 指定Filebeat如何将匹配行组合成事件,在之前或者之后，取决于上面所指定的negate multiline.max_lines 可以组合成一个事件的最大行数，超过将丢弃，默认500 multiline.timeout 定义超时时间，如果开始一个新的事件在超时时间内没有发现匹配，也将发送日志，默认是5s tail_files 如果此选项设置为true，Filebeat将在每个文件的末尾开始读取新文件，而不是开头 此选项适用于Filebeat尚未处理的文件 symlinks 符号链接选项允许Filebeat除常规文件外,可以收集符号链接。收集符号链接时，即使报告了符号链接的路径，Filebeat也会打开并读取原始文件。 backoff backoff选项指定Filebeat如何积极地抓取新文件进行更新。默认1s backoff选项定义Filebeat在达到EOF之后再次检查文件之间等待的时间。 max_backoff 在达到EOF之后再次检查文件之前Filebeat等待的最长时间 backoff_factor 指定backoff尝试等待时间几次，默认是2 harvester_limit harvester_limit选项限制一个prospector并行启动的harvester数量，直接影响文件打开数 enabled 控制prospector的启动和关闭 filebeat globalspool_size 事件发送的阀值，超过阀值，强制刷新网络连接 1filebeat.spool_size: 2048 publish_async 异步发送事件，实验性功能 idle_timeout 事件发送的超时时间，即使没有超过阀值，也会强制刷新网络连接 1filebeat.idle_timeout: 5s registry_file 注册表文件的名称，如果使用相对路径，则被认为是相对于数据路径 有关详细信息，请参阅目录布局部分 默认值为${path.data}/registry 1filebeat.registry_file: registry config_dir 包含额外的prospector配置文件的目录的完整路径 每个配置文件必须以.yml结尾 每个配置文件也必须指定完整的Filebeat配置层次结构，即使只处理文件的prospector部分。 所有全局选项（如spool_size）将被忽略 必须是绝对路径 1filebeat.config_dir: path/to/configs shutdown_timeout Filebeat等待发布者在Filebeat关闭之前完成发送事件的时间。 Filebeat Generalname 设置名字，如果配置为空，则用该服务器的主机名 1name: &quot;my-shipper&quot; queue_size 单个事件内部队列的长度 默认1000 bulk_queue_size 批量事件内部队列的长度 max_procs 设置最大使用cpu数量 geoip.paths 此配置选项目前仅由Packetbeat使用，它将在6.0版中删除 要使GeoIP支持功能正常，GeoLite City数据库是必需的。 1234geoip: paths: - &quot;/usr/share/GeoIP/GeoLiteCity.dat&quot; - &quot;/usr/local/var/GeoIP/GeoLiteCity.dat&quot; Filebeat reload 属于测试功能 path 定义要检查的配置路径 reload.enabled 设置为true时，启用动态配置重新加载。 reload.period 定义要检查的间隔时间 filebeat.config.prospectors: path: configs/*.yml reload.enabled: true reload.period: 10s]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>filebeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filebeat_work]]></title>
    <url>%2F2017%2F06%2F09%2Ffilebeat_work%2F</url>
    <content type="text"><![CDATA[Filebeat work这个话题，你学习了解Filebeat关键构件他们之间是怎么样工作， 理解这些概念，在配置filebeat的时候，帮助你做出正确的决定。 filebeat有俩个主要的组件： prospectors or harversters Harvester 负责读取一个单个文件的内容 逐行读取一个文件，并发送内容到输出端 从文件的开始读取，通过文件描述符控制关闭和打开文件 如果文件被移走或者重命名，依然会读取该文件 默认情况下,Filebeat保持打开该文件,直到到达close_inactive 关闭harverter会有以下结果 如果之前正在读取一个删除的日志文件，此时关闭harverter，则这个文件将被关闭，释放潜在的资源 scan_frequency运行后，将被开始读取文件 当文件被删除或者移走，关闭harvester，文件不在被读取 控制harvester的关闭，使用close_* 选项配置 Prospector 负责管理harvesters和寻找资源来读取 当input_type是log的时候，它将发现所有匹配定义的路径文件，为每个文件开始启动一个harvester，每个prospector都跑自己的例程 支持俩中prospector类型： log and stdin 每个prospector类型可以被定义多次 对每个文件检查是否需要启动harvester，是否已经启动，是否被忽略等定义 如果harvester是关闭的，文件的尺寸改变了，新行只是被收录进来 保持文件状态 保持文件状态，频繁写入registry file中 文件状态记录最后读取文件的偏移量，确保所有日志文件被发送 跟踪发送的最后一行日志，继续阅读日志，直到输出端恢复正常 filebeat运行的时候，每个prospector状态信息被保存在内存中 filebeat被重启，将读取registry文件来恢复文件状态，确认位置 为了发现每个prospertor保持文件状态，对于每个文件，filebeat将存储唯一验证号来探测一个文件是否被获取了 保证至少一次成功投递 filebeat为每个事件存储投递状态到registry file中 在定义的输出被阻塞的情况下并没有证实所有事件,Filebeat将试图发送事件,直到输出承认已收到事件 如果在发送事件中，filebeat关闭，它不会等待事件成功投递返回结果，当再次启动filebeat的时候，会再次发送一次事件，确保至少事件有一次被发送，但也可以在结束的时候，发送俩条事件，或者可以指定等待超时时间 通过shutdown_timeout 限制 当输出端不可达的时候，文件被删除了，数据可能会丢失 写入磁盘的速度一定要大雨filebeat进程的速度 linux上还有可能inode重用，filebeat会跳过inode重用文件]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>filebeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins-gitlab-git pull]]></title>
    <url>%2F2016%2F09%2F08%2Fjenkins-gitlab-git%20pull%2F</url>
    <content type="text"><![CDATA[系统环境12[root@office-docker-registry ]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) 安装gitlabyum安装12345678[root@office-docker-registry ]# cat /etc/yum.repos.d/gitlab-ce.repo [gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7repo_gpgcheck=0gpgcheck=0enabled=1gpgkey=https://packages.gitlab.com/gpg.key 修改配置12345678910111213141516[root@office-docker-registry # vim /etc/gitlab/gitlab.rbexternal_url &apos;http://10.128.28.196&apos;##启动加载reconfigure[root@office-docker-registry ~]# gitlab-ctl reconfigure[root@office-docker-registry ~]# gitlab-ctl status run: gitlab-workhorse: (pid 23500) 617s; run: log: (pid 23438) 658srun: logrotate: (pid 23456) 650s; run: log: (pid 23455) 650srun: nginx: (pid 23444) 656s; run: log: (pid 23443) 656srun: postgresql: (pid 23293) 696s; run: log: (pid 23292) 696srun: redis: (pid 23210) 702s; run: log: (pid 23209) 702srun: sidekiq: (pid 23428) 659s; run: log: (pid 23427) 659srun: unicorn: (pid 23482) 618s; run: log: (pid 23395) 665s## web访问http:://10.128.28.196 安装jenkins安装jdk最新版本12345[root@office-docker-registry ~]# yum install -y java-1.8.0-openjdk[root@office-docker-registry ~]# java -version openjdk version &quot;1.8.0_101&quot;OpenJDK Runtime Environment (build 1.8.0_101-b13)OpenJDK 64-Bit Server VM (build 25.101-b13, mixed mode) yun源jenkins1234wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat-stable/jenkins.reporpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key yum install jenkins -ysystemctl start jenkins 配置jenkins 由于gitlab 的ruby程序也使用8080端口,所以修改jenkins默认配置将端口改为除了8080,80,以外的端口 123456789101112131415161718192021222324252627282930313233[root@office-docker-registry ]# rpm -ql jenkins/etc/init.d/jenkins/etc/logrotate.d/jenkins/etc/sysconfig/jenkins #jenkins默认配置文件路径/usr/lib/jenkins #jenkins家目录/usr/lib/jenkins/jenkins.war/usr/sbin/rcjenkins/var/cache/jenkins/var/lib/jenkins/var/log/jenkins[root@office-docker-registry ]# grep -v &quot;^$&quot; /etc/sysconfig/jenkins |grep -v &quot;^#&quot;JENKINS_HOME=&quot;/data/jenkins&quot; #这里修改了默认的家目录JENKINS_JAVA_CMD=&quot;&quot;JENKINS_USER=&quot;jenkins&quot;JENKINS_JAVA_OPTIONS=&quot;-Djava.awt.headless=true&quot;JENKINS_PORT=&quot;8081&quot; #端口这里修改为8081JENKINS_LISTEN_ADDRESS=&quot;10.128.28.196&quot; #监听地址修改为本地地址JENKINS_HTTPS_PORT=&quot;&quot;JENKINS_HTTPS_KEYSTORE=&quot;&quot;JENKINS_HTTPS_KEYSTORE_PASSWORD=&quot;&quot;JENKINS_HTTPS_LISTEN_ADDRESS=&quot;&quot;JENKINS_DEBUG_LEVEL=&quot;5&quot;JENKINS_ENABLE_ACCESS_LOG=&quot;no&quot;JENKINS_HANDLER_MAX=&quot;100&quot;JENKINS_HANDLER_IDLE=&quot;20&quot;JENKINS_ARGS=&quot;&quot;[root@office-docker-registry data]# mkdir -pv /data/jenkins/ [root@office-docker-registry data]# chown jenkins.jenkins -R /data/jenkins/ [root@office-docker-registry data]# /etc/init.d/jenkins restart #重启jenkins[root@office-docker-registry data]# ss -tunlp | grep 8081 #检查8081端口tcp LISTEN 0 50 ::ffff:10.128.28.196:8081 :::* users:((&quot;java&quot;,pid=26235,fd=20)) 访问jenkins web界面 http://10.128.28.196:8081 登录 12[root@office-docker-registry ~]# cat /data/jenkins/secrets/initialAdminPassword789066937d624c7cafbc503b703c2c08 输入密码继续,点击skip plugin Installaitons 测试发邮件(在下一步插件安装完成后在回来执行这一步骤) 安装插件 此时会默认装上系统默认的插件 使用jenkins 添加一个认证用户,拉取git代码的时候使用 gitlab上操作 gitlab上操作 系统上查看代码 可以看到README.md被拉取下来,内容一致 1234[root@office-docker-registry demo1]# pwd/data/jenkins/workspace/demo1[root@office-docker-registry demo1]# cat README.md test web]]></content>
      <categories>
        <category>git持续集成</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab-git-Install]]></title>
    <url>%2F2016%2F09%2F07%2Fgitlab-git-Install%2F</url>
    <content type="text"><![CDATA[系统环境12[root@office-c6-4 ~]# cat /etc/redhat-release CentOS release 6.6 (Final) yum源gitlab配置12345678[root@office-c6-4 ~]# cat /etc/yum.repos.d/gitlab-ce.repo [gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el6repo_gpgcheck=0 gpgcheck=0 enabled=1 gpgkey=https://packages.gitlab.com/gpg.key 安装gitlab1yum install gitlab-ce-8.10.8* -y 配置gitlab123456789101112external_url &apos;http://192.168.10.14&apos;gitlab_rails[&apos;smtp_enable&apos;] = true #邮件发送设置gitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.163.com&quot;gitlab_rails[&apos;smtp_port&apos;] = 25gitlab_rails[&apos;smtp_user_name&apos;] = &quot;rooroot@163.com&quot;gitlab_rails[&apos;smtp_password&apos;] = &quot;password&quot;gitlab_rails[&apos;smtp_domain&apos;] = &quot;163.com&quot;gitlab_rails[&apos;smtp_authentication&apos;] = :logingitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = truegitlab_rails[&apos;smtp_tls&apos;] = falsegitlab_rails[&apos;gitlab_email_from&apos;] = &quot;rooroot@163.com&quot;user[&quot;git_user_email&quot;] = &quot;rooroot@163.com 配置邮件发送1234[root@office-c6-4 ~]# echo &quot;Test mail from postfix&quot; | mail -s &quot;Test Postfix&quot; budongshu@mia.com-bash: mail: command not found[root@office-c6-4 ~]# yum install mailx -y [root@office-c6-4 ~]# echo &quot;Test mail from postfix&quot; | mail -s &quot;Test Postfix&quot; budongshu@xxxxxxx.com 启动并查看gitlab状态123456789[root@office-c6-4 ~]# gitlab-ctl reconfigure[root@office-c6-4 ~]# gitlab-ctl status run: gitlab-workhorse: (pid 1650) 264s; run: log: (pid 1546) 348srun: logrotate: (pid 1564) 340s; run: log: (pid 1563) 340srun: nginx: (pid 1552) 346s; run: log: (pid 1551) 346srun: postgresql: (pid 1401) 392s; run: log: (pid 1400) 392srun: redis: (pid 1318) 398s; run: log: (pid 1317) 398srun: sidekiq: (pid 1536) 354s; run: log: (pid 1535) 354srun: unicorn: (pid 1737) 199s; run: log: (pid 1503) 356s 访问界面 如若出现界面502的情况，请检查本地是否配置nginx,还有80,8080端口是否被占用1http://192.168.10.14 web界面访问 首次登陆会提示让其设置新密码 创建用户 创建一个组并加入dev成员 创建一个project 客户端安装git-1.9 默认git-1.7，yum装的有些问题，所以升级到1.9 123456789yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMakercd /usr/srcwget https://www.kernel.org/pub/software/scm/git/git-1.9.4.tar.gztar xzf git-1.9.4.tar.gzcd git-1.9.4make prefix=/usr/local/git allmake prefix=/usr/local/git installecho &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/bashrcsource /etc/bashrc 客户端git下载上传git clone(root管理员用户)123456789[root@office-c6-2 data]# git clone http://192.168.10.14/ops/testconfig.git Cloning into &apos;testconfig&apos;...Username for &apos;http://192.168.10.14&apos;: root #输入用户名Password for &apos;http://root@192.168.10.14&apos;: #输入密码remote: Counting objects: 6, done.remote: Compressing objects: 100% (3/3), done.remote: Total 6 (delta 0), reused 0 (delta 0)Unpacking objects: 100% (6/6), done.Checking connectivity... done. git clone(dev 组中的一个开发人员)1234567891011121314[root@office-c6-2 ops]# git clone http://192.168.10.14/ops/testconfig.git Cloning into &apos;testconfig&apos;...Username for &apos;http://192.168.10.14&apos;: budongshu #输入的是dev开发者的用户（不是root用户）Password for &apos;http://budongshu@192.168.10.14&apos;: #该用户的密码remote: Counting objects: 13, done.remote: Compressing objects: 100% (8/8), done.remote: Total 13 (delta 0), reused 0 (delta 0)Unpacking objects: 100% (13/13), done.Checking connectivity... done.[root@office-c6-2 ops]# ll -ls testconfig/total 84 -rw-r--r-- 1 root root 48 Sep 10 01:12 nginx.conf4 -rw-r--r-- 1 root root 15 Sep 10 01:12 README.md 建立分支 非组的admin管理员不可以将代码直接push到master分支上，需要建立一个分支确认测试代码没有问题后，在进行合并merge 123456789101112131415161718192021222324252627282930313233343536[root@office-c6-2 testconfig]# git config --global user.name &quot;budongshu&quot;[root@office-c6-2 testconfig]# git config --global user.email &quot;admin@126.com&quot;[root@office-c6-2 testconfig]# touch db.conf #新建一个配置文件（随意的，测试使用）[root@office-c6-2 testconfig]# echo &quot;listen 3306&quot; &gt;&gt; db.conf [root@office-c6-2 testconfig]# git branch dev #新建dev 分支[root@office-c6-2 testconfig]# git checkout dev #切换到dev分支Switched to branch &apos;dev&apos; [root@office-c6-2 testconfig]# git push origin dev #将本地push到远程originUsername for &apos;http://192.168.10.14&apos;: budongshu Password for &apos;http://budongshu@192.168.10.14&apos;: Total 0 (delta 0), reused 0 (delta 0)To http://192.168.10.14/ops/testconfig.git 38982eb..4205f58 dev -&gt; dev[root@office-c6-2 testconfig]# echo &quot;ip 0.0.0.0 &quot; &gt;&gt; db.conf #修改配置文件[root@office-c6-2 testconfig]# git add db.conf #添加到暂存区[root@office-c6-2 testconfig]# git status #查看状态On branch devChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: db.conf[root@office-c6-2 testconfig]# git commit -m &quot;add db.conf &quot; #提交[dev e198869] add db.conf 1 file changed, 2 insertions(+) create mode 100644 db.conf[root@office-c6-2 testconfig]# git push -u origin dev #push到远程分支dev下Username for &apos;http://192.168.10.14&apos;: budongshuPassword for &apos;http://budongshu@192.168.10.14&apos;: Counting objects: 5, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 319 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To http://192.168.10.14/ops/testconfig.git 4205f58..e198869 dev -&gt; devBranch dev set up to track remote branch dev from origin web界面查看 可以看到db.conf新建的文件已经上传到dev分支下面,如果测试没问后,在merge到master主分支上. over]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elk-redis]]></title>
    <url>%2F2016%2F09%2F06%2Felk-redis%2F</url>
    <content type="text"><![CDATA[前期规划 10.128.28.196 (nginx + apahe logstash收集日志(shipper)) 10.128.28.197 (redis + logstash 获取日志(indexer)) 10.128.28.198 (elasticsearch + kibana ) 系统版本12cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) logstash安装logstash 采用配置yum源的方式安装logstash 12345678[root@office-docker-registry]# cat /etc/yum.repos.d/logstash.repo [logstash-2.3]name=Logstash repository for 2.3.x packagesbaseurl=https://packages.elastic.co/logstash/2.3/centosgpgcheck=1gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearchenabled=1[root@office-docker-registry ~]# yum install -y logstash 配置logstash 默认配置文件路径,默认是没有任何配置的 1234567891011121314151617[root@office-docker-registryr ~]# rpm -ql logstash | grep /etc/logstash /etc/logstash/conf.d[root@office-docker-registry ~]# cd /etc/logstash/conf.d/[root@office-docker-registry conf.d]# vim simple.conf [root@office-docker-registry conf.d]# cat simple.conf input &#123; stdin&#123;&#125; &#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125; 测试配置文件格式是否正确12[root@office-docker-registry conf.d]# logstash -f simple.conf --configtestConfiguration OK 写个hello world 玩玩 依赖java 启动加载比较慢可以看下输出的格式 12345678910111213[root@office-docker-registry conf.d]# logstash -f simple.conf Settings: Default pipeline workers: 1Pipeline main startedhello world #手动输入hello world 按回车返回以下信息&#123; &quot;message&quot; =&gt; &quot;hello world&quot;, #输入的信息 &quot;@version&quot; =&gt; &quot;1&quot;, #版本 &quot;@timestamp&quot; =&gt; &quot;2016-09-06T14:33:18.647Z&quot;, &quot;host&quot; =&gt; &quot;mesos-master&quot; #主机名&#125;安ctrl + d 退出 安装httpd12[root@office-docker-registry ~]# yum install -y httpd[root@office-docker-registry ~]# systemctl start httpd apache 日志格式1LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined apache 输出日志110.128.0.12 - - [06/Sep/2016:21:17:01 +0800] &quot;GET /noindex/css/open-sans.css HTTP/1.1&quot; 304 - &quot;http://10.128.28.196/&quot; &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:48.0) Gecko/20100101 Firefox/48.0&quot; logstash收集apache日志 如下可以看到grok-patterns,该文件提供了apache的grok匹配,只需要引用相关变量即可 12[root@office-docker-registry conf.d]# rpm -ql logstash | grep grok-patterns/opt/logstash/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-2.0.2/patterns/grok-patterns 收集apapche日志配置如下(输出到终端测试) 12345678910111213141516171819202122232425262728293031323334353637383940[root@office-docker-registry conf.d]# cat apachesimple2.conf input &#123; file &#123; path =&gt; &quot;/var/log/httpd/access_log&quot; start_position =&gt; &quot;beginning&quot; type =&gt; &quot;apache-access&quot; &#125; &#125;filter &#123; if [type] == &apos;apache-access&apos; &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125; overwrite =&gt; [ &quot;message&quot; ] remove_field =&gt; [&quot;message&quot; ] &#125; date &#123; match =&gt; [&quot;timestamp&quot; , &quot;dd/MMM/YYYY:HH:mm:ss Z&quot;] &#125; urldecode &#123; all_fields =&gt; true &#125; mutate &#123; convert =&gt; &#123;&quot;response&quot; =&gt; &quot;integer&quot;&#125; convert =&gt; &#123;&quot;bytes&quot; =&gt; &quot;integer&quot;&#125; gsub =&gt; [ &quot;referrer&quot;,&apos;\&quot;&apos;, &quot;&quot;, &quot;agent&quot;,&apos;\&quot;&apos;,&quot;&quot; ] &#125; &#125;&#125; output &#123; stdout &#123; codec =&gt; rubydebug &#125; &#125; 先加上 —configtest进行测试,没问题后在执行 123456789101112131415161718192021[root@office-docker-registry conf.d]# /opt/logstash/bin/logstash -f apachesimple2.conf Settings: Default pipeline workers: 1Logstash startup completed&#123; &quot;@version&quot; =&gt; &quot;1&quot;, &quot;@timestamp&quot; =&gt; &quot;2016-09-06T14:01:45.000Z&quot;, &quot;path&quot; =&gt; &quot;/var/log/httpd/access_log&quot;, &quot;host&quot; =&gt; &quot;0.0.0.0&quot;, &quot;type&quot; =&gt; &quot;apache-access&quot;, &quot;clientip&quot; =&gt; &quot;172.16.96.36&quot;, &quot;ident&quot; =&gt; &quot;-&quot;, &quot;auth&quot; =&gt; &quot;-&quot;, &quot;timestamp&quot; =&gt; &quot;06/Sep/2016:22:01:45 +0800&quot;, &quot;verb&quot; =&gt; &quot;GET&quot;, &quot;request&quot; =&gt; &quot;/&quot;, &quot;httpversion&quot; =&gt; &quot;1.1&quot;, &quot;response&quot; =&gt; 403, &quot;bytes&quot; =&gt; 4897, &quot;referrer&quot; =&gt; &quot;-&quot;, &quot;agent&quot; =&gt; &quot;curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.21 Basic ECC zlib/1.2.3 libidn/1.18 libssh2/1.4.2&quot;&#125; 安装nginx yum安装比较方便,为了测试 12yum install nginx -ysystemctl start nginx #启动nginx(这里要注意nginx和httpd记得修改监听端口,避免重复) nginx 日志格式(这里根据需要,我修改了默认格式,自定义日志格式) nginx监听在81端口 12345log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &quot;$http_cookie&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &apos; &apos;$upstream_addr $upstream_status $upstream_cache_status &apos; &apos;$request_time&apos;; nginx 输出格式110.128.0.12 - - [06/Sep/2016:21:49:54 +0800] &quot;GET /poweredby.png HTTP/1.1&quot; 304 0 &quot;http://10.128.28.196:81/&quot; &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:48.0) Gecko/20100101 Firefox/48.0&quot; &quot;-&quot; - - - 0.000 logstash 收集nginx日志 需要自定义模式,grok-patterns自带的正则不满足nginx日志需求新建目录,存放自定义匹配nginx日志的模式文件nginxlog 12345[root@office-docker-registry conf.d]# mkdir /opt/logstash/patterns/[root@office-docker-registry conf.d]# cd /opt/logstash/patterns/[root@office-docker-registry patterns]# cat nginxlogNGINXACCESS %&#123;IP:remote_ip&#125; (%&#123;USER:ident&#125;|-&#125;) (%&#123;USER:auth&#125;|-) \[%&#123;HTTPDATE:timestamp&#125;\] &quot;%&#123;WORD:method&#125; %&#123;NOTSPACE:request&#125; (?:HTTP/%&#123;NUMBER:httpversion&#125;)&quot; %&#123;NUMBER:status&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QS:referer&#125; %&#123;QS:http_cookie&#125; %&#123;QS:ua&#125; %&#123;QS:xff&#125; (%&#123;URIHOST:upstream_host&#125;|-) (%&#123;NUMBER:upstream_response&#125;|-) (%&#123;WORD:upstream_cache_status&#125;|-) (%&#123;BASE16FLOAT:request_time&#125;|-) 收集nginx配置如下(输出到终端测试) 1234567891011121314151617181920212223242526272829303132333435363738[root@office-docker-registry conf.d]# cat nginx2.conf input &#123; file &#123; path =&gt; &quot;/var/log/nginx/access.log&quot; start_position =&gt; &quot;beginning&quot; &#125; &#125;filter &#123; grok &#123; patterns_dir =&gt; &quot;/opt/logstash/patterns/nginxlog&quot; #指定寻找nginxlog匹配模式的路径 match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;NGINXACCESS&#125;&quot; &#125; #引用名称(相当于这个模式匹配的名称) remove_field =&gt; [&quot;message&quot; ] #移除message,避免重复输出俩次 &#125; date &#123; match =&gt; [&quot;timestamp&quot; , &quot;dd/MMM/YYYY:HH:mm:ss Z&quot;] &#125; urldecode &#123; all_fields =&gt; true &#125; mutate &#123; convert =&gt; &#123;&quot;response&quot; =&gt; &quot;integer&quot;&#125; #repsonse字段 变成整数 convert =&gt; &#123;&quot;bytes&quot; =&gt; &quot;integer&quot;&#125; #bytes字段 变成整数 gsub =&gt; [ &quot;referer&quot;,&apos;\&quot;&apos;, &quot;&quot;, #替换referer字段的\&quot; 为 空 &quot;ua&quot;,&apos;\&quot;&apos;,&quot;&quot;, &quot;xff&quot;,&apos;\&quot;&apos;,&quot;&quot; ] &#125;&#125; output &#123; stdout &#123; codec =&gt; rubydebug #输出到终端 &#125; &#125; 加上 —configtest测试没问题后在执行 1234567891011121314151617181920212223[root@office-docker-registry ~]# /opt/logstash/bin/logstash -f /etc/logstash/conf.d/nginx3.conf Settings: Default pipeline workers: 1Logstash startup completed&#123; &quot;@version&quot; =&gt; &quot;1&quot;, &quot;@timestamp&quot; =&gt; &quot;2016-09-07T00:21:46.000Z&quot;, &quot;path&quot; =&gt; &quot;/var/log/nginx/access.log&quot;, &quot;host&quot; =&gt; &quot;0.0.0.0&quot;, &quot;remote_ip&quot; =&gt; &quot;10.128.0.12&quot;, &quot;ident&quot; =&gt; &quot;-&quot;, &quot;auth&quot; =&gt; &quot;-&quot;, &quot;timestamp&quot; =&gt; &quot;07/Sep/2016:08:21:46 +0800&quot;, &quot;method&quot; =&gt; &quot;GET&quot;, &quot;request&quot; =&gt; &quot;/&quot;, &quot;httpversion&quot; =&gt; &quot;1.1&quot;, &quot;status&quot; =&gt; &quot;200&quot;, &quot;bytes&quot; =&gt; 3700, &quot;referer&quot; =&gt; &quot;-&quot;, &quot;http_cookie&quot; =&gt; &quot;\&quot;-\&quot;&quot;, &quot;ua&quot; =&gt; &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.6.1000 Chrome/30.0.1599.101 Safari/537.36&quot;, &quot;xff&quot; =&gt; &quot;-&quot;, &quot;request_time&quot; =&gt; &quot;0.000&quot;&#125; 额外提供nginx 原始日志匹配 提供nginx原始标准日志格式匹配. 123456789#yum装完,不做改变,原始标准日志格式log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;#nginx 输出格式10.128.0.12 - - [07/Sep/2016:08:27:59 +0800] &quot;GET / HTTP/1.1&quot; 200 3700 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.6.1000 Chrome/30.0.1599.101 Safari/537.36&quot; &quot;-&quot;#nginx匹配NGINXACCESS %&#123;IP:remote_ip&#125; (%&#123;USER:ident&#125;|-) (%&#123;USER:auth&#125;|-) \[%&#123;HTTPDATE:timestamp&#125;\] &quot;%&#123;WORD:method&#125; %&#123;NOTSPACE:request&#125; (?:HTTP/%&#123;NUMBER:httpversion&#125;)&quot; %&#123;NUMBER:status&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QS:referer&#125; %&#123;QS:http_cookie&#125; %&#123;QS:ua&#125; %&#123;QS:xff 安装supervisord (报错有点问题,待解决)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@office-docker-registry conf.d]# yum install supervisor -y[root@office-docker-registry conf.d]# vim /etc/supervisord.d/logstash.ini [root@office-docker-registry supervisord.d]# cat logstash.ini [program:logstash-nginx]command=/opt/logstash/bin/logstash -f /etc/logstash/conf.d/nginx3-to-redis.confautostart=trueautorestart=truestartsecs=20stdout_logfile=/opt/logstash/logs/logstash_nginx_stdout.logstdout_logfile_maxbytes=1MBstdout_logfile_backups=10stdout_capture_maxbytes=1MBstdout_events_enabled=falsestderr_logfile=/opt/logstash/logs/logstash_nginx_stderr.logstderr_logfile_maxbytes=1MBstderr_logfile_backups=10stderr_capture_maxbytes=1MBstderr_events_enabled=false[program:logstash-apache]command=/opt/logstash/bin/logstash -f /etc/logstash/conf.d/apachesimple2.confautostart=trueautorestart=truestartsecs=20stdout_logfile=/opt/logstash/logs/logstash_apache_stdout.logstdout_logfile_maxbytes=1MBstdout_logfile_backups=10stdout_capture_maxbytes=1MBstdout_events_enabled=falsestderr_logfile=/opt/logstash/logs/logstash_apache_stderr.logstderr_logfile_maxbytes=1MBstderr_logfile_backups=10stderr_capture_maxbytes=1MBstderr_events_enabled=false[root@office-docker-registry conf.d]# mkdir /opt/logstash/logs -pv [root@office-docker-registry supervisord.d]# systemctl start supervisord [root@office-docker-registry supervisord.d]# systemctl status supervisord ● supervisord.service - Process Monitoring and Control Daemon Loaded: loaded (/usr/lib/systemd/system/supervisord.service; disabled; vendor preset: disabled) Active: active (running) since Tue 2016-09-06 23:46:42 CST; 6s ago Process: 7108 ExecStart=/usr/bin/supervisord -c /etc/supervisord.conf (code=exited, status=0/SUCCESS) Main PID: 7111 (supervisord) Memory: 202.0M CGroup: /system.slice/supervisord.service ├─7111 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf ├─7112 /usr/bin/java -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -Djava.awt.headless=true -XX:CMSInitiatingOccupancyFraction=75 -X... └─7113 /usr/bin/java -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -Djava.awt.headless=true -XX:CMSInitiatingOccupancyFraction=75 -X...Sep 06 23:46:42 office-docker-registry systemd[1]: Starting Process Monitoring and Control Daemon...Sep 06 23:46:42 office-docker-registry systemd[1]: Started Process Monitoring and Control Daemon. 采用开俩个终端分别启动logstash收集nginx和apache nginx 1234567891011121314151617181920212223242526272829303132333435363738394041input &#123; file &#123; path =&gt; &quot;/var/log/nginx/access.log&quot; start_position =&gt; &quot;beginning&quot; type =&gt; &quot;nginx-access&quot;&#125;&#125;filter &#123; grok &#123; patterns_dir =&gt; &quot;/opt/logstash/patterns/nginxlog3&quot; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;NGINXACCESS&#125;&quot; &#125; overwrite =&gt; [ &quot;message&quot; ] remove_field =&gt; [&quot;message&quot; ] &#125; date &#123; match =&gt; [&quot;timestamp&quot; , &quot;dd/MMM/YYYY:HH:mm:ss Z&quot;] &#125; urldecode &#123; all_fields =&gt; true &#125; mutate &#123; convert =&gt; &#123;&quot;response&quot; =&gt; &quot;integer&quot;&#125; convert =&gt; &#123;&quot;bytes&quot; =&gt; &quot;integer&quot;&#125; gsub =&gt; [ &quot;referer&quot;,&apos;\&quot;&apos;, &quot;&quot;, &quot;ua&quot;,&apos;\&quot;&apos;,&quot;&quot;, &quot;xff&quot;,&apos;\&quot;&apos;,&quot;&quot; ] &#125;&#125; output &#123; redis &#123; data_type =&gt; &quot;list&quot; key =&gt; &quot;nginx-access&quot; host =&gt; &quot;10.128.28.197&quot; port =&gt; 6379 workers =&gt; 5 &#125;&#125;#启动/opt/logstash/bin/logstash -f /etc/logstash/conf.d/nginx-to-redis.conf apache 123456789101112131415161718192021222324252627282930313233343536373839404142input &#123; file &#123; path =&gt; &quot;/var/log/httpd/access_log&quot; start_position =&gt; &quot;beginning&quot; type =&gt; &quot;apache-access&quot; &#125; &#125;filter &#123; if [type] == &quot;apache-access&quot; &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125; overwrite =&gt; [ &quot;message&quot; ] remove_field =&gt; [&quot;message&quot; ] &#125; date &#123; match =&gt; [&quot;timestamp&quot; , &quot;dd/MMM/YYYY:HH:mm:ss Z&quot;] &#125; urldecode &#123; all_fields =&gt; true &#125; mutate &#123; convert =&gt; &#123;&quot;response&quot; =&gt; &quot;integer&quot;&#125; convert =&gt; &#123;&quot;bytes&quot; =&gt; &quot;integer&quot;&#125; gsub =&gt; [ &quot;referrer&quot;,&apos;\&quot;&apos;, &quot;&quot;, &quot;agent&quot;,&apos;\&quot;&apos;,&quot;&quot; ] &#125; &#125; &#125; output &#123; redis &#123; data_type =&gt; &quot;list&quot; key =&gt; &quot;apache-access&quot; host =&gt; &quot;10.128.28.197&quot; port =&gt; 6379 workers =&gt; 5 &#125;&#125;#启动/opt/logstash/bin/logstash -f /etc/logstash/conf.d/apache-to-redis.conf 安装redis123456789101112131415161718192021wget wget http://download.redis.io/releases/redis-3.2.1.tar.gz tar xf redis-3.2.1.tar.gz -C /usr/local/cd /usr/local/mv redis-3.2.1 rediscd redismake &amp;&amp; make install cd /usr/local/redis/src cp redis-cli redis-server /usr/bin/vim /usr/local/redis/redis.conf #编辑配置文件 daemonize yes #是否以后台daemon方式运行，默认不是后台运行 pidfile /var/run/redis/redis.pid #redis的PID文件路径 bind 10.128.28.197 #绑定主机IP，默认值为127.0.0.1，我们是跨机器运行，所以需要 logfile /data/logs/redis/redis.log #定义log文件位置，模式log信息定向到stdout，输出到/dev/null save 60 1000 #重新定义快照的频率 dir /data/redis/ #定义data目录mkdir /var/run/redismkdir /data/logs/redis/ -pvmkdir /data/redisredis-server /usr/local/redis/redis.conf 安装logtash-indexer同上面一样 配置logstash获取nginx+apache的日志 12345678910111213141516171819202122232425262728293031323334cat /etc/logstash/conf.d/server.conf input &#123; redis &#123; data_type =&gt; &quot;list&quot; key =&gt; &quot;nginx-access&quot; host =&gt; &quot;10.128.28.197&quot; port =&gt; 6379 threads =&gt; 5 &#125; redis &#123; data_type =&gt; &quot;list&quot; key =&gt; &quot;apache-access&quot; host =&gt; &quot;10.128.28.197&quot; port =&gt; 6379 threads =&gt; 5 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;10.128.28.198:9200&quot;] index =&gt; &quot;logstash-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;type&#125;&quot; workers =&gt; 5 flush_size =&gt; 3000 template_overwrite =&gt; true&#125;&#125;#启动/opt/logstash/bin/logstash -f /etc/logstash/conf.d/server.conf 查看redis 开始访问nginx和apache页面 12345678910111213(integer) 1127.0.0.1:6379&gt; LLEN nginx-access(integer) 1127.0.0.1:6379&gt; LLEN nginx-access(integer) 187127.0.0.1:6379&gt; LLEN apache-access(integer) 364127.0.0.1:6379&gt; LLEN nginx-access(integer) 279127.0.0.1:6379&gt; LINDEX nginx-access 0 &quot;&#123;\&quot;@version\&quot;:\&quot;1\&quot;,\&quot;@timestamp\&quot;:\&quot;2016-09-06T15:32:06.000Z\&quot;,\&quot;path\&quot;:\&quot;/var/log/nginx/access.log\&quot;,\&quot;host\&quot;:\&quot;0.0.0.0\&quot;,\&quot;type\&quot;:\&quot;nginx-access\&quot;,\&quot;remote_ip\&quot;:\&quot;10.128.28.196\&quot;,\&quot;ident\&quot;:\&quot;-\&quot;,\&quot;auth\&quot;:\&quot;-\&quot;,\&quot;timestamp\&quot;:\&quot;06/Sep/2016:23:32:06 +0800\&quot;,\&quot;method\&quot;:\&quot;HEAD\&quot;,\&quot;request\&quot;:\&quot;/\&quot;,\&quot;httpversion\&quot;:\&quot;1.1\&quot;,\&quot;status\&quot;:\&quot;200\&quot;,\&quot;bytes\&quot;:0,\&quot;referer\&quot;:\&quot;-\&quot;,\&quot;http_cookie\&quot;:\&quot;\\\&quot;-\\\&quot;\&quot;,\&quot;ua\&quot;:\&quot;curl/7.29.0\&quot;,\&quot;xff\&quot;:\&quot;-\&quot;,\&quot;request_time\&quot;:\&quot;0.000\&quot;&#125;&quot;127.0.0.1:6379&gt; LINDEX nginx-access 0 &quot;&#123;\&quot;@version\&quot;:\&quot;1\&quot;,\&quot;@timestamp\&quot;:\&quot;2016-09-06T15:32:06.000Z\&quot;,\&quot;path\&quot;:\&quot;/var/log/nginx/access.log\&quot;,\&quot;host\&quot;:\&quot;0.0.0.0\&quot;,\&quot;type\&quot;:\&quot;nginx-access\&quot;,\&quot;remote_ip\&quot;:\&quot;10.128.28.196\&quot;,\&quot;ident\&quot;:\&quot;-\&quot;,\&quot;auth\&quot;:\&quot;-\&quot;,\&quot;timestamp\&quot;:\&quot;06/Sep/2016:23:32:06 +0800\&quot;,\&quot;method\&quot;:\&quot;HEAD\&quot;,\&quot;request\&quot;:\&quot;/\&quot;,\&quot;httpversion\&quot;:\&quot;1.1\&quot;,\&quot;status\&quot;:\&quot;200\&quot;,\&quot;bytes\&quot;:0,\&quot;referer\&quot;:\&quot;-\&quot;,\&quot;http_cookie\&quot;:\&quot;\\\&quot;-\\\&quot;\&quot;,\&quot;ua\&quot;:\&quot;curl/7.29.0\&quot;,\&quot;xff\&quot;:\&quot;-\&quot;,\&quot;request_time\&quot;:\&quot;0.000\&quot;&#125; 安装elasticsearch123456789[root@localhost ~]# cat /etc/yum.repos.d/elasticsearch.repo [elasticsearch-2.x]name=Elasticsearch repository for 2.x packagesbaseurl=https://packages.elastic.co/elasticsearch/2.x/centosgpgcheck=1gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearchenabled=1yum install -y elasticsearch elasticsearch修改配置文件 这里先不使用集群,单机做测试 123456789101112131415161718192021222324252627[root@office-28-198 ~]# grep -v &quot;^#&quot; /etc/elasticsearch/elasticsearch.yml | grep -v &quot;^$&quot;path.data: /data/elk/datapath.logs: /data/elk/logsbootstrap。mlockall: truehttp.port: 9200network.host: 10.128.28.198[root@office-28-198 ~]# mkdir -pv /data/elk/&#123;data,logs&#125; #安装插件[root@office-28-198 ~]# /usr/share/elasticsearch/bin/plugin install mobz/elasticsearc-head [root@office-28-198 ~]# /usr/share/elasticsearch/bin/plugin install lmenezes/elasticsearch-kopf#启动[root@office-28-198 ~]# systemctl start elasticsearch [root@office-28-198 ~]# systemctl status elasticsearch #测试一下[root@office-28-198 ~]# curl http://10.128.28.198:9200&#123; &quot;name&quot; : &quot;Black Talon&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;2.3.5&quot;, &quot;build_hash&quot; : &quot;90f439ff60a3c0f497f91663701e64ccd01edbb4&quot;, &quot;build_timestamp&quot; : &quot;2016-07-27T10:36:52Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;5.5.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 安装kinana123456789[root@localhost]# cat /etc/yum.repos.d/kibana.repo [kibana-4.5]name=Kibana repository for 4.5.x packagesbaseurl=http://packages.elastic.co/kibana/4.5/centosgpgcheck=1gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearchenabled=1yum install -y kibana 修改配置,连接elasticsearch 1234[root@office-28-198 ~]# vim /opt/kibana/config/kibana.yml elasticsearch.url: &quot;http://10.128.28.198:9200&quot;[root@office-28-198 ~]# systemctl start kibana[root@office-28-198 ~]# systemctl status kibana 访问 1http://10.128.28.198:5601 如图]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL5.6主从复制及读写分离的实现]]></title>
    <url>%2F2016%2F09%2F06%2FMySQL5.6_%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8F%8A%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[MySQL5.6主从复制及读写分离的实现 MySQL 5.6 基于GTID的主从复制及使用amoeba配置实现读写分离** amoeba 简介Amoeba(变形虫)项目,该开源框架于2008年开始发布一款 Amoeba forMysql软件。这个软件致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的时候充当SQL路由功能，专注于分布式数据库代理层（Database Proxy）开发。座落与 Client、DB Server(s)之间,对客户端透明。具有负载均衡、高可用性、SQL 过滤、读写分离、可路由相关的到目标数据库、可并发请求多台数据库合并结果。通过Amoeba你能够完成多数据源的高可用、负载均衡、数据切片的功能，目前Amoeba已在很多企业的生产线上面使用 Amoeba优点： 1.降低费用，简单易用2.提高系统整体可用性3.易于扩展处理能力和系统规模4.可以直接实现读写分离及负载均衡的效果，而不用修改代码 Amoeba 缺点： 1.不支持事务与存储过程2.暂不支持分库分表，amoeba目前只做到分数据库实例3.不适合从amoeba导入数据的场景或者对大数据量查询的query并不合适（比如一次请求返回10w以上的甚至更多的数据场合） MySQL GTIDMysql 5.6的新特性之一，加入了全局事务性ID(GTID:GlobalTransactions Identifier)来强化数据库的主备一致性，故障恢复，以及容错能力;也使得复制功能的配置、监控及管理变得更加易于实现，且更加健壮 MySQL主从配置 环境介绍： 12[root@master~]# 192.168.17.15[root@slave~]# 192.168.17.32 安装mysql服务器在俩台主机上 12345678910111213tar xfmysql-5.6.13-linux-glibc2.5-x86_64.tar.gz -C /usr/localcd /usr/local/ln -sv mysql-5.6.13-linux-glibc2.5-x86_64/mysqlcd mysqlchown –R root.msyql *cp support-files/mysql.server/etc/init.d/mysqldchmod +x /etc/init.d/mysqldchkconfig --add mysqldchkconfig mysqld onecho"PATH=/usr/local/mysql/bin:$PATH" &gt; /etc/profile. /etc/profilecat /etc/my.cnf | egrep -v "^#"&gt; /root/my.cnfcp /root/my.cnf /etc/ 主/etc/my.cnf的配置文件总汇 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[client]port = 3306socket = /tmp/mysql.sock[mysqld]port = 3306socket = /tmp/mysql.sockskip-external-lockingkey_buffer_size = 256Mmax_allowed_packet = 1Mtable_open_cache = 256sort_buffer_size = 1Mread_buffer_size = 1Mread_rnd_buffer_size = 4Mmyisam_sort_buffer_size = 64Mthread_cache_size = 8query_cache_size= 16Mthread_concurrency = 8datadir=/mydata/datainnodb_file_per_table = 1log-bin=/binlog/mysql-binbinlog_format=rowlog-slave-updates=truegtid-mode=onenforce-gtid-consistency=truemaster-info-repository=TABLErelay-log-info-repository=TABLEsync-master-info=1slave-parallel-workers=2binlog-checksum=CRC32master-verify-checksum=1slave-sql-verify-checksum=1binlog-rows-query-log_events=1report-port=3306report-host=192.168.17.32server-id = 20[mysqldump]quickmax_allowed_packet = 16M[mysql]no-auto-rehash[myisamchk]key_buffer_size = 128Msort_buffer_size = 128Mread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeout 初始化mysql并启动 12345678910chown -R mysql.mysql /mydata/data/chown -R mysql.mysql /binlog/./scripts/mysql_install_db --user=mysql--datadir=/mydata/data/service mysqld start``` &gt;slave服务器安装mysql与master一样 ，但在slave服务器的/etc/my.cnf配置文件中有俩个参数需要更改一下与master服务器不同```pythonserver-id = 20 report-host = 192.168.17.32 在master服务器上创建slave复制用户并测试连接 123mysql&gt; grant replication client,replication slave on *.* to 'slave'@'192.168.%.%' identified by 'budongshu';mysql&gt; flush privileges;[root@slave mysql]# mysql -uslave-pbudongshu -h 192.168.17.15 #成功连接 启动从节点的复制线程 123456789[root@slave mysql]# mysqlmysql&gt; change master tomaster_host='192.168.17.15', -&gt; master_user='slave', -&gt; master_password='budongshu', -&gt; master_auto_position=1;mysql&gt; start slave;mysql&gt; show slave status \G Slave_IO_Running: YesSlave_SQL_Running:Yes yes代表启动成功,必须要俩个全部都是yes 在master服务器创建数据库查看slave服务器是否更新 12345678910111213141516171819202122[root@master ~]# mysql -e 'create databasebds1'[root@slave mysql]# mysql -e 'showdatabases'+--------------------+| Database |+--------------------+| information_schema || bds || bds1 | #slave服务器同步正常| mysql || performance_schema || test |+--------------------+mysql&gt; show processlist; #查看gtid进程+----+-------------+-----------+------+---------+---------+-----------------------------------------------------------------------------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+-------------+-----------+------+---------+---------+-----------------------------------------------------------------------------+------------------+| 4| system user | | NULL |Connect | 395 | Waiting for master tosend event | NULL || 5| system user | | NULL |Connect | 225 | Slave has read allrelay log; waiting for the slave I/O thread to update it | NULL || 6| system user | | NULL |Connect | -252924 | Waiting for an event from Coordinator | NULL || 7| system user | | NULL |Connect | -253320 | Waiting for an event from Coordinator | NULL || 9| root | localhost | NULL |Query | 0 | init |show processlist |+----+-------------+-----------+------+---------+---------+-----------------------------------------------------------------------------+------------------+ 读写分离配置基于前面做的mysql主从架构，然后在前端加一台服务器，用于实现mysql的读分离， 安装jdk (bin结尾的包，rpm包都可以,可以去oracle官网下载) 12345678910[root@amoeba ~]# chmod +x jdk-6u31-linux-x64-rpm.bin[root@amoeba ~]#. /jdk-6u31-linux-x64-rpm.bin[root@amoeba ~]# vim /etc/profile.d/java.shexport JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:$PATH[root@amoeba ~]#. /etc/profile.d/java.sh[root@amoeba ~]# java -versionjava version "1.6.0_31"Java(TM) SE Runtime Environment (build1.6.0_31-b04)Java HotSpot(TM) 64-Bit Server VM (build20.6-b01, mixed mode) 安装amoeba 12345678[root@amoeba ~]# mkdir /usr/local/amoeba[root@amoeba ~]# tar xf amoeba-mysql-binary-2.2.0.tar.gz -C /usr/local/[root@amoeba ~]# vi/etc/profile.d/amoeba.shexport AMOEBA_HOME=/usr/local/amoebaexport PATH=$AMOEBA_HOME/bin:$PATH[root@amoeba ~]# . /etc/profile.d/amoeba.sh[root@amoeba ~]# amoeba #出现下边信息代表安装成功amoeba start|stop 授权MySQL用户，用于实现前端amoeba连接 12mysql&gt; grant all on *.* to'amoeba'@'192.168.%.%' identified by 'amoebapass';mysql&gt; flush privileges; 配置amoeba 123[root@amoeba ~]# cd /usr/local/amoeba/conf/amoeba.xml #定义管理信息与读写分离dbServers.xml #定义后端服务器的配置 配置文件dbServers.xml介绍 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@amoeba conf]# vi dbServers.xml&lt;?xml version="1.0"encoding="gbk"?&gt;&lt;!DOCTYPE amoeba:dbServers SYSTEM"dbserver.dtd"&gt;&lt;amoeba:dbServersxmlns:amoeba="http://amoeba.meidusa.com/"&gt; &lt;!-- Each dbServer needs tobe configured into a Pool, If you need toconfigure multiple dbServer with load balancing that can be simplified by thefollowing configuration: add attribute with name virtual ="true" in dbServer, but the configuration does not allow the elementwith name factoryConfig such as 'multiPool'dbServer --&gt; &lt;dbServer name="abstractServer" abstractive="true"&gt; &lt;factoryConfigclass="com.meidusa.amoeba.mysql.net.MysqlServerConnectionFactory"&gt; &lt;propertyname="manager"&gt;$&#123;defaultManager&#125;&lt;/property&gt; &lt;propertyname="sendBufferSize"&gt;64&lt;/property&gt; &lt;propertyname="receiveBufferSize"&gt;128&lt;/property&gt; &lt;!-- mysql port--&gt; &lt;propertyname="port"&gt;3306&lt;/property&gt; #连接后端mysql服务器的端口 &lt;!-- mysql schema--&gt; &lt;propertyname="schema"&gt;test&lt;/property&gt; #连接后端mysql服务器的默认库 &lt;!-- mysql user--&gt; &lt;propertyname="user"&gt;amoeba&lt;/property&gt; #连接后端mysql服务器的用户名 &lt;!-- mysql password --&gt; #把password最后的注释(--&gt;)这个符号去掉跟上边一样 &lt;propertyname="password"&gt;amoebapass&lt;/propert&gt; #连接后端mysql服务器的密码 &lt;/factoryConfig&gt; &lt;poolConfigclass="com.meidusa.amoeba.net.poolable.PoolableObjectPool"&gt; &lt;propertyname="maxActive"&gt;500&lt;/property&gt; &lt;propertyname="maxIdle"&gt;500&lt;/property&gt; &lt;propertyname="minIdle"&gt;10&lt;/property&gt; &lt;propertyname="minEvictableIdleTimeMillis"&gt;600000&lt;/property&gt; &lt;propertyname="timeBetweenEvictionRunsMillis"&gt;600000&lt;/property&gt; &lt;propertyname="testOnBorrow"&gt;true&lt;/property&gt; &lt;propertyname="testOnReturn"&gt;true&lt;/property&gt; &lt;propertyname="testWhileIdle"&gt;true&lt;/property&gt; &lt;/poolConfig&gt; &lt;/dbServer&gt; &lt;dbServer name="master" parent="abstractServer"&gt; #定义master服务器的节点 name可以自定义 &lt;factoryConfig&gt; &lt;!-- mysql ip --&gt; &lt;propertyname="ipAddress"&gt;192.168.17.15&lt;/property&gt; #定义master服务器的IP地址 &lt;/factoryConfig&gt; &lt;/dbServer&gt; &lt;dbServer name="slave" parent="abstractServer"&gt; #定义slave服务器的节点 &lt;factoryConfig&gt; &lt;!-- mysql ip --&gt; &lt;propertyname="ipAddress"&gt;192.168.17.32&lt;/property&gt; &lt;/factoryConfig&gt; &lt;/dbServer&gt; &lt;dbServer name="multiPool" virtual="true"&gt; &lt;poolConfigclass="com.meidusa.amoeba.server.MultipleServerPool"&gt; &lt;!-- Load balancingstrategy: 1=ROUNDROBIN , 2=WEIGHTBASED , 3=HA--&gt; #负载均衡算法 &lt;propertyname="loadbalance"&gt;1&lt;/property&gt; #定义选择哪一种算法 &lt;!-- Separated bycommas,such as: server1,server2,server1 --&gt; #定义数据库池，用于实现负载均衡，“slave“为自定义的数据库节点，可以写多个用”，”隔开 &lt;property name="poolNames"&gt;slave&lt;/property &lt;/poolConfig&gt; &lt;/dbServer&gt;&lt;/amoeba:dbServers&gt; 配置文件amoeba.xml 介绍 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899[root@amoeba conf]# vi amoeba.xml&lt;?xml version="1.0"encoding="gbk"?&gt;&lt;!DOCTYPE amoeba:configuration SYSTEM"amoeba.dtd"&gt;&lt;amoeba:configurationxmlns:amoeba="http://amoeba.meidusa.com/"&gt; &lt;proxy&gt; &lt;!-- service class mustimplements com.meidusa.amoeba.service.Service --&gt; &lt;servicename="Amoeba for Mysql"class="com.meidusa.amoeba.net.ServerableConnectionManager"&gt; &lt;!-- port --&gt; &lt;propertyname="port"&gt;3306&lt;/property&gt; #定义amoeba代理服务器对外监听的端口 &lt;!-- bind ipAddress--&gt; &lt;!-- &lt;propertyname="ipAddress"&gt;192.168.17.11&lt;/property&gt; #定义amoeba代理服务器对外连接的监听ip --&gt; &lt;propertyname="manager"&gt;$&#123;clientConnectioneManager&#125;&lt;/property&gt; &lt;propertyname="connectionFactory"&gt; &lt;beanclass="com.meidusa.amoeba.mysql.net.MysqlClientConnectionFactory"&gt; &lt;property name="sendBufferSize"&gt;128&lt;/property&gt; &lt;property name="receiveBufferSize"&gt;64&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;propertyname="authenticator"&gt; &lt;beanclass="com.meidusa.amoeba.mysql.server.MysqlClientAuthenticator"&gt; #定义客户端使用的用户名和密码 &lt;property name="user"&gt;admin&lt;/property&gt; &lt;property name="password"&gt;password&lt;/property&gt; &lt;property name="filter"&gt; &lt;beanclass="com.meidusa.amoeba.server.IPAccessController"&gt; &lt;propertyname="ipFile"&gt;$&#123;amoeba.home&#125;/conf/access_list.conf&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/service&gt; &lt;!-- server class mustimplements com.meidusa.amoeba.service.Service --&gt; &lt;service name="AmoebaMonitor Server"class="com.meidusa.amoeba.monitor.MonitorServer"&gt; &lt;!-- port --&gt; &lt;!-- default value: random number &lt;propertyname="port"&gt;9066&lt;/property&gt; --&gt; &lt;!-- bind ipAddress--&gt; &lt;propertyname="ipAddress"&gt;127.0.0.1&lt;/property&gt; &lt;propertyname="daemon"&gt;true&lt;/property&gt; &lt;propertyname="manager"&gt;$&#123;clientConnectioneManager&#125;&lt;/property&gt; &lt;propertyname="connectionFactory"&gt; &lt;beanclass="com.meidusa.amoeba.monitor.net.MonitorClientConnectionFactory"&gt;&lt;/bean&gt; &lt;/property&gt; &lt;/service&gt; &lt;runtimeclass="com.meidusa.amoeba.mysql.context.MysqlRuntimeContext"&gt; &lt;!-- proxy servernet IO Read thread size --&gt; &lt;propertyname="readThreadPoolSize"&gt;20&lt;/property&gt; &lt;!-- proxy serverclient process thread size --&gt; &lt;propertyname="clientSideThreadPoolSize"&gt;30&lt;/property&gt; &lt;!-- mysql serverdata packet process thread size --&gt; &lt;propertyname="serverSideThreadPoolSize"&gt;30&lt;/property&gt; &lt;!-- per connectioncache prepared statement size --&gt; &lt;propertyname="statementCacheSize"&gt;500&lt;/property&gt; &lt;!-- query timeout(default: 60 second , TimeUnit:second) --&gt; &lt;propertyname="queryTimeout"&gt;60&lt;/property&gt; &lt;/runtime&gt; &lt;/proxy&gt; &lt;!-- Each ConnectionManager willstart as thread manager responsible for theConnection IO read , Death Detection --&gt; &lt;connectionManagerList&gt; &lt;connectionManagername="clientConnectioneManager"class="com.meidusa.amoeba.net.MultiConnectionManagerWrapper"&gt; &lt;propertyname="subManagerClassName"&gt;com.meidusa.amoeba.net.ConnectionManager&lt;/property&gt; &lt;!-- default value isavaliable Processors &lt;propertyname="processors"&gt;5&lt;/property&gt; --&gt; &lt;/connectionManager&gt; &lt;connectionManagername="defaultManager" class="com.meidusa.amoeba.net.MultiConnectionManagerWrapper"&gt; &lt;propertyname="subManagerClassName"&gt;com.meidusa.amoeba.net.AuthingableConnectionManager&lt;/property&gt; &lt;!-- default value is avaliableProcessors &lt;propertyname="processors"&gt;5&lt;/property&gt; --&gt; &lt;/connectionManager&gt; &lt;/connectionManagerList&gt; &lt;!-- default using fileloader --&gt; &lt;dbServerLoader class="com.meidusa.amoeba.context.DBServerConfigFileLoader"&gt; &lt;propertyname="configFile"&gt;$&#123;amoeba.home&#125;/conf/dbServers.xml&lt;/property&gt; &lt;/dbServerLoader&gt; &lt;queryRouterclass="com.meidusa.amoeba.mysql.parser.MysqlQueryRouter"&gt; &lt;propertyname="ruleLoader"&gt; &lt;beanclass="com.meidusa.amoeba.route.TableRuleFileLoader"&gt; &lt;propertyname="ruleFile"&gt;$&#123;amoeba.home&#125;/conf/rule.xml&lt;/property&gt; &lt;propertyname="functionFile"&gt;$&#123;amoeba.home&#125;/conf/ruleFunctionMap.xml&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;propertyname="sqlFunctionFile"&gt;$&#123;amoeba.home&#125;/conf/functionMap.xml&lt;/property&gt; &lt;propertyname="LRUMapSize"&gt;1500&lt;/property&gt; &lt;propertyname="defaultPool"&gt;master&lt;/property&gt; #把 &lt;!-- --&gt;注释去掉使其配置生效, 定义默认池，默认会在此服务器上执行 &lt;property name="writePool"&gt;master&lt;/property&gt; #定义只写服务器 &lt;propertyname="readPool"&gt;slave&lt;/property&gt; #定义只读服务器，也可以在dbServer.xml中定义数据池的名称，实现负载均衡 &lt;propertyname="needParse"&gt;true&lt;/property&gt; &lt;/queryRouter&gt;&lt;/amoeba:configuration&gt; 启动amoeba服务并测试 123[root@amoeba conf]# amoeba start &amp; #后台启动amoeba[root@amoeba conf]# ss -tunlp | grep 3306 #启动正常tcp LISTEN 0 128 :::3306 :::* users:(("java",1796,52)) 连接amoeba代理服务器，执行插入和查询操作，分别在后端俩台服务器进行抓包，查看是否实现读写分离 1234mysql&gt; create database bds2;mysql&gt; use bds2mysql&gt; create table tb2 (id int ) ;mysql&gt; select * from tb2; tcpdump抓包查看检测123456789101112131415161718192021222324[root@master ~]# tcpdump -i eth0 -s0 -nn -A tcp dst port 3306 and dst host192.168.17.15 13:25:46.488469 IP 192.168.17.11.39787 &gt;192.168.17.15.3306: Flags [P.], seq 171:202, ack 444, win 490, options[nop,nop,TS val 8050703 ecr 15047099], length 31E..S4 @.@.c1.........k....z..y..............z...........create table tb2 (id int ) ###写请求在master服务器上执行13:25:46.523028 IP 192.168.17.32.41112 &gt;192.168.17.15.3306: Flags [.], ack 1661, win 1117, options [nop,nop,TS val41437531 ecr 15058573], length 0E..4..@.@.y&#123;... ........M.$....4...]. ......xI[....13:25:46.523050 IP 192.168.17.11.39787 &gt;192.168.17.15.3306: Flags [.], ack 455, win 490, options [nop,nop,TS val 8050737ecr 15058574], length 0E..44@.@.cO.........k....z..y......Q.......z.1.... [root@slave ~]# tcpdump -i eth0 -s0 -nn -Atcp dst port 3306 and dst host 192.168.17.32 15:01:20.243577 IP 192.168.17.11.54071 &gt;192.168.17.32.3306: Flags [.], ack 196, win 457, options [nop,nop,TS val8129871 ecr 41516665], length 0E..4@.@.@.V&#125;....... .7..&#125;. ....i...........O.y~y15:01:20.246139 IP 192.168.17.11.54071 &gt;192.168.17.32.3306: Flags [P.], seq 133:155, ack 196, win 457, options[nop,nop,TS val 8129874 ecr 41516665], length 22E..J@.@.@.Vf....... .7..&#125;. ....i...........R.y~y.....select * from tb2 ###读请求在slave服务器上执行15:01:20.287625 IP 192.168.17.11.54071 &gt;192.168.17.32.3306: Flags [.], ack 259, win 457, options [nop,nop,TS val8129915 ecr 41516669], length 0E..4@.@.@.V&#123;....... .7..&#125;. ..........&#125;.....&#123;.y~&#125; 由上图可知抓包实现了读写分离的效果]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7编译安装zabbix3.0]]></title>
    <url>%2F2016%2F09%2F02%2FCentos7_install%E7%BC%96%E8%AF%91zabbix3.0%2F</url>
    <content type="text"><![CDATA[zabbix 系统环境1234[root@localhost ~]# uname -a Linux localhost.localdomain 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux[root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) 安装yum源12[root@localhost ~]# wget -P /etc/yum.repos.d http://mirrors.aliyun.com/repo/Centos-7.repo[root@localhost ~]# yum install -y epel* lamp环境说明 zabbix3.0不能直接在centos6上以rpm包的形式安装,所以系统环境是centos7的,如果要在centos6上安装采用编译的形式安装,这里centos7,我也使用编译安装的方式,同时zabbix3.0要求php的版本比较高注意php的版本 centos7的mysql用的是mariadb12345678910[root@localhost ~]# yum search mysql |grep mariadbRepository base is listed more than once in the configurationRepository updates is listed more than once in the configurationRepository extras is listed more than once in the configurationRepository centosplus is listed more than once in the configurationmariadb.x86_64 : A community developed branch of MySQLmariadb-devel.i686 : Files for development of MariaDB/MySQL applicationsmariadb-devel.x86_64 : Files for development of MariaDB/MySQL applicationsmariadb-libs.i686 : The shared libraries required for MariaDB/MySQL clientsmariadb-libs.x86_64 : The shared libraries required for MariaDB/MySQL clients 安装lamp12[root@localhost ~]# yum -y install mariadb mariadb-server php php-mysql httpd mysql-devel libxml2-devel \libcurl-devel net-snmp-devel libxml2-devel libXpm php-bcmath php-gd php-mbstring php-xml t1lib 软件版本 启动服务1234启动mariadb[root@localhost ~]# systemctl enable mariadb Created symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service.[root@localhost ~]# systemctl start mariadb 配置设置数据库root密码和初始化安全设置 第一个红框表示: 现在的默认的root用户的密码,直接回车就好.因为默认root用户没有密码 第二个红框表示: 为root设置一个密码 第一个 是否移除匿名用户 第二个 是否允许root远程访问 第三个 移除test测试数据库 第四个 重新加载 建立zabbix数据库和授权访问12[root@localhost ~]# mysql -uroot -pmysql -e &quot;create database zabbix default character set utf8 collate utf8_bin;&quot; [root@localhost ~]# mysql -uroot -pmysql -e &quot;grant all on zabbix.* to &apos;zabbix&apos;@localhost identified by &apos;zabbix&apos;;&quot; 测试配置 启动服务1systemctl start httpd lamp 安装完毕 安装编译zabbix3.0下载加压123[root@localhost ~]# wget http://jaist.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/3.0.4/zabbix-3.0.4.tar.gz[root@localhost ~]# tar xf zabbix-3.0.4.tar.gz [root@localhost ~]# cd /root/zabbix-3.0.4/database/mysql 拷贝sql到zabbix数据库123[root@localhost mysql]# mysql -uzabbix -pzabbix zabbix &lt; schema.sql [root@localhost mysql]# mysql -uzabbix -pzabbix zabbix &lt; images.sql [root@localhost mysql]# mysql -uzabbix -pzabbix zabbix &lt; data.sql 编译zabbix3.012[root@localhost zabbix-3.0.4]# ./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --enable-proxy --with-libxml2[root@localhost zabbix-3.0.4]# make &amp;&amp; make install 修改zabbix配置文件123456789101112[root@localhost ~]# grep -v &quot;^#&quot; /usr/local/zabbix/etc/zabbix_server.conf |grep -v &quot;^$&quot;LogFile=/tmp/zabbix_server.logDBName=zabbixDBUser=zabbixDBPassword=zabbixDBPort=3306StartPollers=5ListenIP=192.168.199.211Timeout=4AlertScriptsPath=/usr/local/zabbix/share/zabbix/alertscriptsExternalScripts=/usr/local/zabbix/share/zabbix/externalscriptsLogSlowQueries=3000 开机自启动12[root@localhost ~]# sed -i &apos;$a /usr/local/zabbix/sbin/zabbix_server -c /usr/local/zabbix/etc/zabbix_server.conf&apos; /etc/rc.local [root@localhost ~]# chmod +x /etc/rc.d/rc.local 拷贝页面文件到站点目录1234[root@localhost ~]# mkdir /data/webroot -pv #把zabbix站点放到此目录[root@localhost ~]# cp -r /root/zabbix-3.0.4/frontends/php/ /data/webroot/zabbix重启httpd[root@localhost zabbix]# service httpd restart 修改httpd配置文件123456789101112131415161718192021222324252627[root@localhost ~]# cd /etc/httpd/conf.d/[root@localhost conf.d]# cat zabbix.conf &lt;VirtualHost 192.168.199.211:80&gt; DocumentRoot /data/webroot/zabbix ServerName bds.zabbix.com DirectoryIndex index.php index.html ErrorLog logs/zabbix-error.log CustomLog logs/zabbix-access.log common&lt;Directory &quot;/data/webroot/zabbix&quot;&gt; Options None AllowOverride None Require ip 192.168.0 #访问控制ip Require all granted &lt;IfModule mod_php5.c&gt; php_value max_execution_time 300 php_value memory_limit 128M php_value post_max_size 16M php_value upload_max_filesize 2M php_value max_input_time 300 php_value always_populate_raw_post_data -1 php_value date.timezone Asia/Chongqing &lt;/IfModule&gt;&lt;/Directory&gt;&lt;/VirtualHost&gt;再次重启httpd[root@localhost zabbix]# service httpd restart web界面安装 在windows主机做本地hosts解析路径: C:\Windows\System32\drivers\etc 修改hosts文件在最后加一条 192.168.199.211 bds.zabbix.com ###请换成你自己的ip地址 按照提示download下载配置文件,然后上传到/data/webroot/zabbix/conf/ 目录下再把zabbix.conf.php 里面$ZBX_SERVER = ‘localhost’;改成自己的ip地址$ZBX_SERVER = ‘192.168.199.211’;注意: 需要跟你的zabbix_server.conf配置文件中,配置的主机地址一致最后刷新页面]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cisco-kron+tftp备份配置]]></title>
    <url>%2F2016%2F09%2F02%2Fcisco-kron-tftp%E5%A4%87%E4%BB%BD%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[linux+tftp+kron 备份cisco交换机配置cisco设备自带kron命令+TFTP/FTP/HTTP 这种备份方式比较简单，但是有一定的局限性。因为kron命令在比较新的IOS版本上才有，有些说在12.3（4）以上才有我测试的版本是12.2(33)，也有这个命令但是kron命令本身并不能自动按照当前日期来命名备份文件所以还需要脚本来帮助wanc 网络设备操作kron命令详细可参考使用kron命令配置自动备份任务计划 kron policy-list backup #创建任务计划 cli write #保存当前网络设备配置，以防止备份信息不完整 cli show run | redirect tftp://172.16.20.223/switch1.cfg #switch1.cfg为备份文件名，不同设备使用不同的备份文件名 exit kron occurrence backup at 00:01 1 recurring #每月1日00:01执行备份 policy-list backup #启动计划任务 exit 查看任务计划 使用do show kron schedule命令可以查看计划任务 1do show kron schedule linux系统操作安装tftp服务1yum -y install tftp tftp-server xinetd 配置tftp服务 修改/etc/xinetd.d/tftp文件，设置TFTP服务器的根目录为/backup/tftpboot/ 1234567891011121314vim /etc/xinetd.d/tftpservice tftp&#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /backup/tftpboot -c #-c 允许客户端上传文件 disable = no #开启服务 per_source = 11 cps = 100 2 flags = IPv4&#125; 创建tftp服务器目录12mkdir –pv /backup/tftpboot/backupchmod o+w /backup/tftpboot 启动tftp服务器，设置开机自启动12service xinetd startchkconfig xinetd on 关闭iptables和selinux 避免因权限的问题 1234service iptables stopstenforce 0ckconfig iptables offsed -i &apos;s/^SELINUX=.*$/SELINUX=disabled/&apos; /etc/selinux/config 创建备份文件自动重命名脚本1234567891011121314vim /backup/tftpboot/backup/switch.sh脚本内容如下： #!/bin/bash#Program:Mv the backup file Date=`date +%F`#备份目录FileDir=/backup/tftpboot#重命名之后文件所在目录BackDir=/backup/tftpboot/backupfor file in `ls $FileDir`;do if [ -f $&#123;FileDir&#125;/$&#123;file&#125; ] ; then mv $&#123;FileDir&#125;/$&#123;file&#125; $&#123;BackDir&#125;/$&#123;Date&#125;-$&#123;file&#125; &amp;&amp; echo &quot;Backup success &quot; &gt;&gt; $&#123;BackDir&#125;/backup.log fidone 脚本定时执行 赋予脚本执行权限，添加到任务计划每月1号2点0分执行备份脚本 1234chmod +x /backup/tftpboot/backup/switch.shecho &apos;0 2 1 * * /bin/sh /backup/tftpboot/backup/switch.sh &gt; /dev/null 2&gt;&amp;1&apos; &gt;&gt; /var/spool/cron/rootchmod 600 /var/spool/cron/rootservice cron restart]]></content>
      <categories>
        <category>cisco</category>
      </categories>
      <tags>
        <tag>cisco</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-pyenv多版本使用]]></title>
    <url>%2F2016%2F09%2F01%2Fpython-pyenv%E5%A4%9A%E7%89%88%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[python pyenv的使用系统环境12[root@office-c6-2 testvirtual]# cat /etc/redhat-release CentOS release 6.6 (Final) epel源1wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repo yum解决依赖1yum install git gcc make patch zlib-devel gdbm-devel openssl-devel sqlite-devel bizp2-devel readline-devel python-pip pyenv安装1curl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash pyenv 环境变量12345678910cat&gt;&gt;.bashrc&lt;&lt;EOFexport PYENV_ROOT=&quot;\$HOME/.pyenv&quot;export PATH=&quot;\$PYENV_ROOT/bin:\$PATH&quot;eval &quot;\$(pyenv init -)&quot;eval &quot;\$(pyenv virtualenv-init -)&quot;EOF#source .bashrc#exec $&#123;SHELL&#125; pyenv介绍123456789101112131415[root@office-c6-2 ~]# pyenv -hUsage: pyenv &lt;command&gt; [&lt;args&gt;]Some useful pyenv commands are: commands List all available pyenv commands local Set or show the local application-specific Python version global Set or show the global Python version shell Set or show the shell-specific Python version install Install a Python version using python-build uninstall Uninstall a specific Python version rehash Rehash pyenv shims (run this after installing executables) version Show the current Python version and its origin versions List all Python versions available to pyenv which Display the full path to an executable whence List all Python versions that contain the given executable local: 本地 global： 全局 shell： shell命令行 version： 当前再用的python版本 前面带*符号的表示当前再用 versions: 所有再用的python版本 rehash： 每次装完python安装包的时候，需要执行以下 install： 安装python包 pyenv使用 程序会从网上下载对应版本的安装包下载到/tmp/python-build当前时间戳如果网络不好，可以在.pyenv/cache 新建这个目录，把相应的源码包放到目录下，通过校验没问题，就可以编译安装。 12345678910pyenv install --list | grep 3.3pyenv install 3.3.5 -v /tmp/python-build.20160901190614.60286 ~/.pyenv/srcDownloading Python-3.3.5.tgz...-&gt; https://www.python.org/ftp/python/3.3.5/Python-3.3.5.tgz0/tmp/python-build.20160901190614.60286/Python-3.3.5 /tmp/python-build.20160901190614.60286 ~/.pyenv/srcInstalling Python-3.3.5...patching file ./Lib/ssl.py..... pyenv virtual 版本目录隔离 基本命令12345678910111213141516171819202122232425[root@office-c6-2 ~]# mkdir testvirtual[root@office-c6-2 ~]# cd testvirtual/[root@office-c6-2 testvirtual]# pyenv virtualenv 3.3.5 env3.3.5-2 Installing pip from https://bootstrap.pypa.io/get-pip.py...Collecting pip Using cached pip-8.1.2-py2.py3-none-any.whlCollecting setuptools Using cached setuptools-26.1.1-py2.py3-none-any.whlCollecting wheel Using cached wheel-0.29.0-py2.py3-none-any.whlInstalling collected packages: pip, setuptools, wheelSuccessfully installed pip-8.1.2 setuptools-26.1.1 wheel-0.29.0[root@office-c6-2 testvirtual]# pyenv versions* system (set by /root/.pyenv/version) 3.3.5 3.3.5/envs/env3.3.5 3.3.5/envs/env3.3.5-2 env3.3.5 env3.3.5-2[root@office-c6-2 testvirtual]# pyenv local env3.3.5-2 (env3.3.5-2) [root@office-c6-2 testvirtual]# pythonPython 3.3.5 (default, Sep 1 2016, 19:15:14) [GCC 4.4.7 20120313 (Red Hat 4.4.7-17)] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 切换卸载命令12345678910111213141516171819(env3.3.5-2) [root@office-c6-2 testvirtual]# pyenv local system [root@office-c6-2 testvirtual]# pyenv version system (set by /root/testvirtual/.python-version)[root@office-c6-2 testvirtual]# pyenv versions* system (set by /root/testvirtual/.python-version) 3.3.5 3.3.5/envs/env3.3.5 3.3.5/envs/env3.3.5-2 env3.3.5 env3.3.5-2[root@office-c6-2 testvirtual]# pyenv activate 3.3.5/envs/env3.3.5-2 pyenv-virtualenv: prompt changing will be removed from future release. configure `export PYENV_VIRTUALENV_DISABLE_PROMPT=1&apos; to simulate the behavior.(3.3.5/envs/env3.3.5-2) [root@office-c6-2 testvirtual]# pyenv deactivate [root@office-c6-2 testvirtual]# pyenv uninstall 3.3.5 pyenv-virtualenv: remove /root/.pyenv/versions/3.3.5/envs/env3.3.5? ypyenv-virtualenv: remove /root/.pyenv/versions/3.3.5/envs/env3.3.5-2? ypyenv: remove /root/.pyenv/versions/3.3.5? y[root@office-c6-2 testvirtual]# pyenv versions* system (set by /root/testvirtual/.python-version)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一张图玩转Xmind 思维脑图]]></title>
    <url>%2F2016%2F08%2F31%2Fone%E5%9B%BE%E7%8E%A9%E8%BD%ACXmind-%E6%80%9D%E7%BB%B4%E8%84%91%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[思维脑图介绍 是有效的思维模式，应用于记忆、学习、思考等的思维“地图” 有利于人脑的扩散思维的展开。思维导图已经在全球范围得到广泛应用 新加坡教育部将思维导图列为小学必修科目，大量的500强企业也在学习思维导图， 中国应用思维导图大约也有20多年时间。 作者-东尼·博赞（Tony Buzan） 网上借鉴的图片 看效果 思维脑图软件 人生苦短 我用xmind 下载地址 一张图精通ximnd 详细请看 脑图软件介绍 xmind中文教程 暖乎乎作者图集]]></content>
      <categories>
        <category>工具用法</category>
      </categories>
      <tags>
        <tag>xmind</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown 语法入门]]></title>
    <url>%2F2016%2F08%2F31%2Fmarkdown-%E8%AF%AD%E6%B3%95%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[目录[toc]大标题123456第一级标题=======``` ```markdown第二级标题------ 字段来吧 快活吧反正有大把时光 标题123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 引用1234&gt; 这是一个引用&gt;&gt; 这是一个二级引用&gt;&gt; 回到一级引用 区块引用里面可以嵌套 其他markdown语法，包括标题，列表，代码区块无序列表123- who- pa- who 有序列表1231. who2. pa3. who 代办列表12- [ ] - [x] 代码块(左侧有四个空格)123import osdef sb(): print shuaige 行内代码块1`html` 视频123%[名称](链接地址)%[名称][1][1] : 链接地址 音频123~[名称](链接地址)~[名称][1][1] : 链接地址 附件123=[名称](链接地址)=[名称][1][1] : 链接地址 插入图像1![图片说明](http://ww4.sinaimg.cn/bmiddle/aa397b7fjw1dzplsgpdw5j.jpg) 强调123**看，我变粗了**_看，我变斜了_ 自动连接123[bds博客地址](http://bdshu.top)&lt;http://bdshu.top&gt; 表格123456789|第一| 第二| 第三||:-----:|:-----:|:------:||姓名| 小王| 小李||年龄| 18 | 19|dog | bird | cat----|------|----foo | foo | foobar bar | baz | baz 分割线12---*** 删除线1~~这是一段错误的文本~~ 标签1Tags: 数学 cjk强调1_这里将显示带有衬线字体效果的中文做为强调_ cjk注音标示123&#123;需要被注音标示的内容&#125;(注音标示)&#123;需要被注音标示的内容&#125;[编号][编号]: 注音标示 居中显示文字1-&gt;居中显示的文字&lt;- 对齐显示文字1234:&gt;居左显示的文字&lt;--&gt;居右显示的文字&lt;::&gt;两端对齐显示的文字&lt;:-&gt;居中显示的文字&lt;- 注： 该语法与center语法冲突，两种语法同时开启时，align语法将覆盖center语法。 Markdown 支持以下这些符号 前面加上反斜杠来帮助插入普通的符号： 123456789101112\ 反斜线` 反引号\* 星号_ 底线&#123;&#125; 花括号[] 方括号() 括弧\# 井字号\+ 加号\- 减号. 英文句点! 惊叹号 更多语法参考：流程图语法参考]]></content>
      <categories>
        <category>工具用法</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2015%2F12%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
